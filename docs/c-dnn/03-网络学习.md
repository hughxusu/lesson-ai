# 神经网络的学习

神经网络的学习就是从训练数据中自动获取最优权重参数的过程。

* 神经网络是一种参数学习算法，这些参数是从数据特征中提取出来的。
* 神经网络的学习过程以数据为驱动，则极力避免人为介入。

> [!note]
>
> 如何实现数字图片中“5”的识别

<img src="https://raw.githubusercontent.com/hughxusu/lesson-ai/develop/images/nn/Xnip2024-12-19_16-50-17.jpg" style="zoom:55%;" />

人可以简单地识别出5，但却很难明确说出是基于何种规律而识别出了5，有效的方法是通过数据来解决这个问题。

1. 基本方法：从图像中提取特征量，再用机器学习技术学习这些特征量的模式。

   * 图像中常用的特征，包括：SIFT、SURF 和 HOG等，这种特征可以把图像转换成向量。

   * 常用的机器学习分类器有，SVM、KNN等分类器进行学习。
   * 该方法的存在的问题是，图像转换为特征向量是由人提前设计好的。不同的问题，必须使用合适的特征，才能得到好的结果。

2. 神经网络方法：直接学习图像本身。
   * 特征仍是由人工设计的，但包含在神经网络中。
   * 特征和分类模型都是由机器学习而来。
   * 神经网络的优点是可以将数据作为原始输入，且对所有的问题都可以用同样的流程来解决。

> [!warning]
>
> 深度学习也称为端到端机器学习（end-to-end machine learning ）。端到端的意思，是指从一端到另一端，也就是从原始数据（输入）中获得目标结果（输出）。

<img src="https://raw.githubusercontent.com/hughxusu/lesson-ai/develop/images/nn/1*eh48E1DUcz7uHusyRtIrhQ.png" style="zoom:90%;" />

在机器学习中特征的提取是由专业人士完成的。在深度学习中，特征的提取集成在网络当中。

## 损失函数

损失函数是用来衡量模型神经网络对监督数据拟合程度的指标，衡量的方式是比较网络输出和真实输出的差异。任何机器学习的过程都是最优化目标函数，即最小化损失函数。深度学习中常用的损失函数是：均方误差和交叉熵误差。

<img src="https://raw.githubusercontent.com/hughxusu/lesson-ai/develop/images/nn/pbjttotxrbkzo_3da39941f7b84175a370e2c497011d42.png" style="zoom:60%;" />

### 均方误差

$$
E=\frac{1}{2}\sum_k\left(y_k-t_k\right)^2
$$

* $y_k$表示神经网络的输出。
* $t_k$表示监督数据。
* $k$表示数据的维数。

使用pytroch计算均方误差

```python
import torch
from torch import nn

y1 = torch.tensor([0.1, 0.05, 0.6, 0.0, 0.05, 0.1, 0.0, 0.1, 0.0, 0.0])
y2 = torch.tensor([0.1, 0.05, 0.1, 0.0, 0.05, 0.1, 0.0, 0.6, 0.0, 0.0])
t = torch.tensor([0, 0, 1, 0, 0, 0, 0, 0, 0, 0])

mse = nn.MSELoss()
print(mse(y1, t))
print(mse(y2, t))
```

> [!attention]
>
> 以均方误差为损失函数，当预测值域目标值相差很多时，梯度容易爆炸。梯度爆炸表现在程序上表示计算的结果是数据的溢出。

### 交叉熵损失函数

对于多分类问题交叉熵损失函数表示如下
$$
E=-\sum_kt_k\log y_k
$$

* $\log$表格为以$e$为底数的自然对数。
* $y_k$表示神经网络的输出。
* 交叉熵损失函数中只有标签为1的结果才有输出。

<img src="https://raw.githubusercontent.com/hughxusu/lesson-ai/develop/images/nn/pbjttotxrbkzo_b03f716d013f49748c6652fce356cda7.png" style="zoom:75%;" />

* 输出曲线是递减的。

<img src="https://raw.githubusercontent.com/hughxusu/lesson-ai/develop/images/nn/a8e4252ec69d0c49709eaf37e6b6fd00.jpg" style="zoom:55%;" />

> [!warning]
>
> 多分类问题与二分类问题的损失函数形式有所不同：二分类是对数损失函数；多分类是交叉熵损失函数。

使用pytroch计算交叉熵损失函数，使用`CrossEntropyLoss`时one-hot编码要转换为标签。

```python
loss = nn.CrossEntropyLoss()
label = torch.argmax(t, dim=0)
print(label)
print(loss(y1, label))
print(loss(y2, label))
```

### mini-batch学习

神经网络的学习是从训练数据中选出一批数据（称为 mini-batch，小批量），作为全部数据的“近似”，然后对每个mini-batch进行学习，这种学习方式称为mini-batch学习。

mini-batch的交叉熵损失函数计算公式如下
$$
E=-\frac{1}{N}\sum_n\sum_kt_k^{(n)}\log y_k^{(n)}
$$

* $N$表示样本的总数。
* $t_k^{(n)}$表示第$n$个监督数据的第$k$个元素的值。
* $y_k^{(n)}$表示第$n$个神经网络输出的第$k$个元素的值。

## 梯度

神经网络的学习采用梯度下降算法，与逻辑回归的梯度下降算法一致。设函数公式如下
$$
f(x_0, x_1)=x_0^2+x_1^2 \tag{1}
$$
函数代码为

```python
def f():
    return (x[0]**2 + x[1]**2)
```

该函数的图像如下

<img src="https://raw.githubusercontent.com/hughxusu/lesson-ai/develop/images/nn/Xnip2025-01-14_10-04-59.jpg" style="zoom:45%;" />

### 梯度的计算

对于公式 $(1)$ 梯度可以表示为
$$
\left( \frac{\partial f}{\partial x_0}, \frac{\partial f}{\partial x_1} \right)
$$
使用pytorch实现梯度的计算

```python
def numerical_gradient(func, params, epsilon=1e-4):
    grads = []
    for param in params:
        grad = torch.zeros_like(param)
        
        param_flat = param.flatten()
        grad_flat = grad.flatten()

        for i in range(param_flat.numel()):
            original_value = param_flat[i].item()

            param_flat[i] = original_value + epsilon
            loss1 = func()

            param_flat[i] = original_value - epsilon
            loss2 = func()

            grad_flat[i] = (loss1 - loss2) / (2 * epsilon)
            param_flat[i] = original_value 

        grads.append(grad)
    return grads
```

* 输入`params`是一个`tensor`，表示对该参数计算梯度。
* 返回结果也为一个`tensor`数组，为梯度的值。

测试梯度计算

```python
x = torch.tensor([3.0, 4.0], requires_grad=False)
grads = numerical_gradient(f, [x])
print("x:", x)
print("Numerical gradient:", grads[0])
```

使用Python绘制公式 $(1)$ 的梯度图像

```python
import matplotlib.pyplot as plt
import numpy as np

x = torch.tensor([0.0, 0.0], requires_grad=False) 
x0_range = np.arange(-5, 5, 0.5) 
x1_range = np.arange(-5, 5, 0.5) 

X0_coords = []
X1_coords = []
U_grads = [] 
V_grads = [] 

for x0_val in x0_range:
    for x1_val in x1_range:
        x[0] = x0_val
        x[1] = x1_val
        grads = numerical_gradient(f, [x])
        grad_x0 = -grads[0][0].item()
        grad_x1 = -grads[0][1].item()
        X0_coords.append(x0_val)
        X1_coords.append(x1_val)
        U_grads.append(grad_x0)
        V_grads.append(grad_x1)


plt.figure(figsize=(10, 10))
plt.quiver(X0_coords, X1_coords, U_grads, V_grads, color='red', alpha=0.7, linewidth=0.5)
X, Y = np.meshgrid(np.linspace(-5, 5, 100), np.linspace(-5, 5, 100))
Z = X**2 + Y**2 
plt.contour(X, Y, Z, levels=np.logspace(0, 2, 10), cmap='viridis', alpha=0.5)
plt.xlabel('$x_0$')
plt.ylabel('$x_1$')
plt.title('2D Gradient Directions of $f(x_0, x_1) = x_0^2 + x_1^2$', fontsize=16)
plt.grid(True, linestyle='--')
plt.axhline(0, color='black', linewidth=1)
plt.axvline(0, color='black', linewidth=1)
plt.show()
```

> [!warning]
>
> 梯度下降的方向是各点处的函数值减小最多的方向。

梯度下降算法是寻找梯度为0的点，但当失函数很复杂，参数空间庞大时，函数的极小值、最小值以及鞍点 （saddle point） 的梯度均为0。

* 极小值是局部最小值，也就是限定在某个范围内的最小值。
* 鞍点是从某个方向上看是极大值，从另一个方向上看则是极小值的点。

<img src="https://raw.githubusercontent.com/hughxusu/lesson-ai/develop/images/nn/Saddle_point.png" style="zoom: 40%;" />

当函数很复杂且呈扁平状时，学习可能会进入一个（几乎）平坦的地区，陷入被称为“学习高原”的无法前进的停滞期。在机器学习过程中上述问题，可以通过反复学习和随机初始化等方法解决。公式 $(1)$ 的梯度下降法数学公式为

$$
 x_0 = x_0-\eta\frac{\partial f}{\partial x_0} \\
x_1 = x_1-\eta\frac{\partial f}{\partial x_1}
$$
$\eta$表示学习率。

### 学习算法的实现

神经网络的学习步骤：

1. 从训练数据中随机选出一部分数据，这部分数据称为mini-batch，通过mini-batch的数据减少损失函数的值。
2. 为了降低损失函数的值，要求出各个权重参数的梯度。
3. 将权重参数，沿梯度下降的方向进行微小更新。
4. 重复上述过程，迭代终止条件：
   * 迭代指定多的次数
   * 权重参数减小数量级，小于一定阈值。

上述过程称为随机梯度下降法 （ stochastic gradient descent ），即对随机选择的数据进行的梯度下降法。使用iris数据集来验证网络算法，选择其中两种类别

<img src="https://raw.githubusercontent.com/hughxusu/lesson-ai/develop/images/base/Iris-Dataset-Classification.png" style="zoom:50%;" />

```python
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
import numpy as np

iris = load_iris()
X = iris.data
y = iris.target

indices_0_1 = np.where((y == 0) | (y == 1))[0]
data = X[indices_0_1]
label = y[indices_0_1]

print(data.shape)
print(label.shape)

X_train, X_test, y_train, y_test = train_test_split(data, label, test_size=0.2, random_state=0)
print(X_train.shape)
print(X_test.shape)
print(y_train.shape)
print(y_test.shape)

X_train = torch.from_numpy(X_train).float()
y_train = torch.from_numpy(y_train).long()
print(X_train.shape)
print(y_train.shape)

X_test = torch.from_numpy(X_test).float()
y_test = torch.from_numpy(y_test).long()
print(X_test.shape)
print(y_test.shape)
```

 定义一个3层的神经网络，网络结构如下

<img src="https://raw.githubusercontent.com/hughxusu/lesson-ai/develop/images/nn/Xnip2025-06-04_20-59-38.jpg" style="zoom:65%;" />

定义神经网络参数

```python
torch.manual_seed(42)

def init_params():
    W1 = torch.randn(5, 4, dtype=torch.float32, requires_grad=False) * 0.1
    b1 = torch.randn(5, dtype=torch.float32, requires_grad=False) * 0.1
    W2 = torch.randn(5, 5, dtype=torch.float32, requires_grad=False) * 0.1
    b2 = torch.randn(5, dtype=torch.float32, requires_grad=False) * 0.1
    W3 = torch.randn(1, 5, dtype=torch.float32, requires_grad=False) * 0.1
    b3 = torch.randn(1, dtype=torch.float32, requires_grad=False) * 0.1
    return [W1, b1, W2, b2, W3, b3]
```

前向传播计算

```python
def forward(x, params):
    W1, b1, W2, b2, W3, b3 = params
    z1 = W1 @ x + b1           
    a1 = torch.sigmoid(z1)     
    z2 = W2 @ a1 + b2          
    a2 = torch.sigmoid(z2)     
    z3 = W3 @ a2 + b3          
    y_pred = torch.sigmoid(z3)
    return y_pred.squeeze()
```

更新网络参数

```python
def update_params(params, grads, lr=0.1):
    for p, g in zip(params, grads):
        p -= lr * g
```

训练函数如下

```python
import torch.nn.functional as F

def train(x_all, y_all, epochs=100, lr=0.1, loss_values=None):
    params = init_params()
    N = x_all.shape[0]
    for epoch in range(epochs):
        total_loss = 0.0
        for i in range(N):
            x = x_all[i]
            y_true = y_all[i]

            loss_fn = lambda: F.binary_cross_entropy(forward(x, params), y_true)
            loss = loss_fn()
            total_loss += loss.item()

            grads = numerical_gradient(loss_fn, params)
            update_params(params, grads, lr)

        avg_loss = total_loss / N
        loss_values.append(avg_loss)
        print(f"Epoch {epoch}, Avg Loss: {avg_loss:.6f}")
    return params
```

调用训练函数

```python
%%time
loss_values = []
params = train(X_train, y_train, epochs=20, lr=0.5, loss_values=loss_values)
```

在上面的代码中，每经过一个epoch，会记录损失函数。

> [!warning]
>
> epoch是一个单位，一个epoch表示学习中所有训练数据均被使用过一次时的更新次数。
>
> | 名称      | 定义                                                         |
> | --------- | ------------------------------------------------------------ |
> | epoch     | 使用训练集的全部数据，对模型进行一次完成的训练，称为“一代训练” |
> | batch     | 使用训练集的一小部分数据，对模型参数进行一次更新，这小部分数据称为“一批数据” |
> | iteration | 使用一个batch数据，对模型参数进行一次更新的过程，称为“一次训练” |
>
> 例如：对于10000条训练数据，用大小为100条数据的mini-batch进行学习，重复随机梯度下降法100次，所有的训练数据就都被使用过了。此时，100次就是一个epoch。如果训练10个epoch，就是进行1000训练。

绘制损失函数曲线

```python
plt.figure(figsize=(10, 5))
plt.plot(loss_values, linewidth=3)
plt.grid(True, linestyle='--')
plt.xticks(fontsize=16)
plt.yticks(fontsize=16)
plt.show() 
```

从图中可以发现，损失函数的值在不断减小，表示学习正常进行，即神经网络的权重在逐渐拟合数据。通过反复地向它浇灌数据，神经网络正在逐渐向最优参数靠近。

### 基于测试数据集的评价

神经网络学习的目标是掌握泛化能力，虽然损失函数值减小，表示神经网络的学习正常进行，但由于过拟合现象的存在，不能保证学习的目标是正确的。要评价神经网络的泛化能力，就必须使用测试数据进行预测。

```python
def evaluate(params, x_test, y_test):
    correct = 0
    total = len(y_test)
    for i in range(total):
        x = x_test[i]
        y_true = y_test[i]

        y_pred = forward(x, params)
        predicted_class = y_pred > 0.5

        if predicted_class == y_true.item():
            correct += 1
    acc = correct / total
    print(f"Test Accuracy: {acc * 100:.2f}%")
    
evaluate(params, X_test, y_test)
```

学习过程分析：

1. 在学习过程中首先应该观察loss曲线，如果loss曲线呈现下降趋势，说明训练过程是正确的。如果loss曲线是震荡的而不下降，说明学习过程是错误，要从数据、模型和代码实现上分析问题。
2. 如果loss曲线呈现下降趋势的条件下，观察训练和测试的准确度：
   * 如果训练数据的准确度高，测试数据的准确度低，则为过拟合。
   * 如果练数据的准确度和测试数据的准确度都低，可能是模型不适合。

上面是通过数值微分，计算了神经网络权重参数的梯度，通过梯度不断修改权重来训练神经网络。这种方法存在的问题

* 计算效率低。
* 数值不稳定性，数值微分对$h$的选择非常敏感。
* 无法处理高维数据。
* 不适合大规模数据集。
