# 卷积神经网络

> [!note]
>
> 全连接层在图像分类中存在哪些问题？

1. 需要处理的数据量大、效率低。

2. 图像在维度调整的过程中很难保留原有的特征，导致图像处理的准确率不高。

<img src="https://raw.githubusercontent.com/hughxusu/lesson-ai/develop/images/nn/b09fccaecb414f04cd79019269645a4d.png" style="zoom:55%;" />

上图表示的图像的内容（本质）并没有发生变化，只是位置发生了变化。

图像通常是高、长、通道方向上的 3 维形状。

<img src="https://raw.githubusercontent.com/hughxusu/lesson-ai/develop/images/nn/1*8k6Yk6MhED2SxF2zLctG7g.png" style="zoom:65%;" />

全连接层输入时，需要将3维数据变换为1维数据。这样处理会忽视形状，将全部的输入数据作为相同的神经元（同一维度的神经元）处理，所以无法利用与形状相关的信息。

卷积神经网络（Convolutional Neural Network，CNN）受人类视觉神经系统的启发，设计的神经网络：

1. 从原始信号摄入开始（瞳孔摄入像素 Pixels）。
2. 接着做初步处理（大脑皮层某些细胞发现边缘和方向）。
3. 然后抽象（大脑判定，眼前的物体的形状，是圆形的）。
4. 最后，进一步抽象（大脑进一步判定该物体是只人脸）。

<img src="https://raw.githubusercontent.com/hughxusu/lesson-ai/develop/images/nn/2ae4a200ebd4d85f7f3e1676d2d2ad92.png" style="zoom:50%;" />

CNN主要用于图像识别。在卷积神经网络中增加了卷积层（Convolution层）和池化层（Pooling层）。全连接网络和卷积神经网络的对比如下

<img src="https://raw.githubusercontent.com/hughxusu/lesson-ai/develop/images/nn/conv-net.jpg" style="zoom:55%;" />

## 卷积层

卷积层是卷积神经网络中的核心模块，卷积层的目的是提取输入特征图的特征，卷积核可以提取图像中的边缘信息。

<img src="https://raw.githubusercontent.com/hughxusu/lesson-ai/develop/images/cv/c0a2fb1215a267fdc7a47a87967ddf42.png" style="zoom:60%;" />

### 卷积运算

卷积运算以一定间隔滑动滤波器的窗口，将各个位置上滤波器的元素和输入的对应元素相乘，然后再求和。然后，将这个结果保存到输出的对应位置。向应用了滤波器的数据加上偏置。偏置通常只有1个，这个值会被加到应用了滤波器的所有元素上。

<img src="https://raw.githubusercontent.com/hughxusu/lesson-ai/develop/images/nn/Xnip2025-01-26_10-05-32.jpg" style="zoom:35%;" />

### 填充

在进行卷积层的处理之前，有时要向输入数据的周围填入固定的数据，这称为填充（padding）。

<img src="https://raw.githubusercontent.com/hughxusu/lesson-ai/develop/images/nn/Xnip2025-01-26_10-16-33.jpg" style="zoom:35%;" />

例子中，将填充的幅度设为1，那么相对于输入大小（4, 4），输出大小也保持为原来的（4, 4）。因此，卷积运算就可以在保持空间大小不变的情况下将数据传给下一层。

> [!warning]
>
> 使用填充主要是为了调整输出的大小。

### 步幅

应用滤波器的位置间隔称为步幅（stride）。步幅也可以用于压缩特征。

<img src="https://raw.githubusercontent.com/hughxusu/lesson-ai/develop/images/nn/Xnip2025-01-26_10-28-48.jpg" style="zoom:35%;" />

假设输入图像的宽为$W$、高为$H$，滤波器宽为$FW$、高为$FH$，填充为$P$，步幅为$S$，输出大小宽为$OW$、输出高为$OH$。则输出图像大小计算公式为
$$
OH=\frac{H+2P-FH}{S}+1 \\
OW=\frac{W+2P-FW}{S}+1
$$

### 3维数据的卷积

通道方向上有多个特征图时，会按通道进行输入数据和滤波器的卷积运算，并将结果相加，从而得到输出。

<img src="https://raw.githubusercontent.com/hughxusu/lesson-ai/develop/images/nn/774b5ed379793cc523de04f7070c0405.png" style="zoom:55%;" />

计算过程如下

<img src="https://raw.githubusercontent.com/hughxusu/lesson-ai/develop/images/nn/c054eab712bc1ef974d42ca5022ad58d.png" style="zoom:55%;" />

在3维数据的卷积运算中，输入数据和滤波器的通道数要设为相同的值。对于RGB图像使用一组滤波器输出是二维图像，生成过程如下

<img src="https://raw.githubusercontent.com/hughxusu/lesson-ai/develop/images/nn/Xnip2025-01-26_10-46-40.jpg" style="zoom:35%;" />

卷积处理后的图像称为特征图。当有多个滤波器时生成特征图过程为

<img src="https://raw.githubusercontent.com/hughxusu/lesson-ai/develop/images/nn/Xnip2025-01-26_10-54-39.jpg" style="zoom:35%;" />

给特征图增加偏置之后为

<img src="https://raw.githubusercontent.com/hughxusu/lesson-ai/develop/images/nn/Xnip2025-01-26_10-58-38.jpg" style="zoom:35%;" />

神经网络的处理中进行了将输入数据打包的批处理。批处理按(batch_num, channel, height, width)的顺序保存数据。多数框架中特征图存储的顺序是(batch_num, height, width, channel)

> [!warning]
>
> CNN的训练过程，就是要确定各个滤波器上，最优参数的过程。

感受野（Receptive Field）是指神经网络中神经元看到的输入区域，在卷积神经网络中，特征图上某元素的计算受输入图像上某个区域的影响，这个区域即该元素的感受野。

<img src="https://raw.githubusercontent.com/hughxusu/lesson-ai/develop/images/nn/Q4wXPf.png" style="zoom:45%;" />

一般使用小的卷积核来代替大的卷积核

* 逐渐增加感受野
* 可以使网络层数加深

> [!warning]
>
> 卷积层一般是使通道数变大。

## 池化层

池化是缩小高、长方向上的空间的运算。用于降低图像维度。

<img src="https://raw.githubusercontent.com/hughxusu/lesson-ai/develop/images/nn/Xnip2025-01-26_11-06-27.jpg" style="zoom:35%;" />

上例中，从2×2的区域中取出最大的元素。假设输入图像的宽为$W$、高为$H$，池化宽为$KW$、高为$KH$，填充为$P$，步幅为$S$，输出大小宽为$OW$、输出高为$OH$。池化层计算输出图像的公式为
$$
OH=\frac{H+2P-KH}{S}+1 \\
OW=\frac{W+2P-KW}{S}+1
$$
池化的方法包括：

* Max池化是从目标区域中取出最大值。
* Average池化是计算目标区域的平均值。

池化的特点：

* 池化层没有要学习的参数。
* 经过池化运算，输入数据和输出数据的通道数不会发生变化。
* 对微小的位置变化具有鲁棒性。

> [!warning]
>
> 池化层一般是使特征图变小。

## 全连接层

全连接层位于CNN网络的末端，经过卷积层的特征提取与池化层的降维后，将特征图转换成一维向量送入到全连接层中进行分类或回归的操作。

<img src="https://raw.githubusercontent.com/hughxusu/lesson-ai/develop/images/nn/d6a5dbd69353abfc747bca3f6dff53ea.png" style="zoom:55%;" />

## PyTorch API

### 卷积层

卷积实际计算是，将输入图像按照卷积滤波器的要求展开成矩阵形式。

<img src="https://raw.githubusercontent.com/hughxusu/lesson-ai/develop/images/nn/Xnip2025-01-26_11-20-32.jpg" style="zoom:35%;" />

数据展开后卷积计算会转换成矩阵乘法

<img src="https://raw.githubusercontent.com/hughxusu/lesson-ai/develop/images/nn/Xnip2025-01-26_11-33-10.jpg" style="zoom:35%;" />

PyTorch中[`nn.Conv2d`](https://docs.pytorch.org/docs/stable/generated/torch.nn.Conv2d.html#torch.nn.Conv2d)实现了卷积层

```python
nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding)
nn.Conv2d(1, 6, 3, 1, 'same')
```

* `in_channels`输入图像的通道数量。
* `out_channels`输出图像的通道数量（卷积核的数量）。
* `kernel_size`卷积核的大小。
* `stride`卷积核的步长。
* `padding`边界填充值。

### 池化层

池化的应用区域按通道单独展开。反向传播时，梯度只会传递到最大值的位置，其他位置的梯度为0。

<img src="https://raw.githubusercontent.com/hughxusu/lesson-ai/develop/images/nn/Xnip2025-01-26_12-06-02.jpg" style="zoom:35%;" />

PyTorch中[`nn.MaxPool2d`](https://docs.pytorch.org/docs/stable/generated/torch.nn.MaxPool2d.html#torch.nn.MaxPool2d)实现了最大池化

```python
nn.MaxPool2d(kernel_size, stride)
nn.MaxPool2d(2, 1)
```

* `kernel_size`池化层大小。
* `stride`窗口移动的步长。

PyTorch中[`nn.AvgPool2`](https://docs.pytorch.org/docs/stable/generated/torch.nn.AvgPool2d.html#avgpool2d)平均池化

```python
nn.AvgPool2d(2, 2)
```

## CNN网络实现

### MNIST数据集

MNIST数据集是用手写数字识别的数据集，该数据集包含60000个用于训练的样本和10000个用于测试的样本，图像是固定大小（28$\times$28像素），其值为0到255。sklearn中的`load_digits`是该数据集的子集。

![](https://raw.githubusercontent.com/hughxusu/lesson-ai/develop/images/cv/MnistExamples.png)

加载数据集

```python
from torchvision import datasets, transforms

train = datasets.MNIST(root='./data',
                       train=True,
                       download=True,
                       transform=transforms.ToTensor())
test = datasets.MNIST(root='./data',
                      train=False,
                      download=True,
                      transform=transforms.ToTensor())
print(len(train), len(test))
```

* 分别读取训练数据了测试数据`train`和`test`。
* `root='./data'`指定下载路径。
* `transform`读取数据转换为`tensor`类型，并归一化到0~1之间，784维。

打印数据信息

```python
image, label = train[0]
print(image.shape) 
print(image.max().item())
print(label)
```

`image`时图片信息，`laebel`是标签信息。PyTorch输入的数据形式为

```
[batch, channels, height, width] => [128, 1, 28, 28]
```

这里只取到一条数据，且为黑白图像，数据格式为`[1, 28, 28]`。绘制数据图像

```python
import matplotlib.pyplot as plt

plt.figure(figsize=(8, 8))
for i in range(9):
    image, label = train[i]
    image = image[0, :, :]
    plt.subplot(3, 3, i+1)
    plt.imshow(image, cmap='gray', interpolation='none')
    plt.title("number {}".format(label), fontsize=16)

plt.tight_layout()
plt.show()
```

将数据包装成`DataLoader`形式才可以进行训练，打印每个batch的数据格式

```python
import torch
from torch.utils.data import random_split
from torch.utils.data import DataLoader

batch_size = 128
valid_size = 10000
train_size = len(full) - valid_size
train, valid = random_split(
    full, [train_size , valid_size], 
    generator=torch.Generator().manual_seed(42)
)
print(len(train), len(valid), len(test))

train_loader = DataLoader(train, batch_size=batch_size, shuffle=True)
data_iter = iter(train_loader)
image, label = next(data_iter)
print(image.shape)
print(label.shape)
```

* `generator=torch.Generator().manual_seed(42)`保证每次训练模型划分数据集的形式是一致的。

### LeNet

LeNet是1989年，贝尔实验室的研究员Yann LeCun提出的，进行手写数字识别的网络，这是现代卷积神经网络的鼻祖。1998年，LeNet进行了改进，形成了现在通用的LeNet-5。

> [!warning]
>
> 卷积神经网络统计网络层数，只计算卷积层和全连接层。

<img src="https://raw.githubusercontent.com/hughxusu/lesson-ai/develop/images/nn/Xnip2025-01-27_16-03-50.jpg" style="zoom:35%;" />

LeNet的特点：

1. 一共有7层，两个卷积层，两个池化层，两个全连接层，一个输出层。
2. 使用sigmoid函数，为激活函数。
3. 使用5$\times$5大小的卷积核。
4. 使用子采样（subsampling）缩小中间数据的大小。

> [!warning]
>
> 在卷积神经网络中：卷积层的功能是特征提取；全连接层的功能是分类

### 子类构建模型

PyTorch构建网络的另一种方式为继承，继承`nn.Module`类，在`__init__`函数中定义网络层，在`forward`方法中定义网络的前向传播过程。

```python
from torch import nn

class LeNet(nn.Module):
    def __init__(self):
        super(LeNet, self).__init__()

        self.c1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5, padding=2)
        self.p1 = nn.AvgPool2d(kernel_size=2, stride=2)
        self.c2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5)
        self.p2 = nn.AvgPool2d(kernel_size=2, stride=2)

        self.flatten = nn.Flatten()
        self.f1 = nn.Linear(16 * 5 * 5, 120)  # 16 channels * 5x5 feature map
        self.f2 = nn.Linear(120, 84)
        self.f3 = nn.Linear(84, 10)

    def forward(self, x):
        x = nn.Sigmoid()(self.c1(x))
        x = self.p1(x)
        x = nn.Sigmoid()(self.c2(x))
        x = self.p2(x)
        x = self.flatten(x)
        x = nn.Sigmoid()(self.f1(x))
        x = nn.Sigmoid()(self.f2(x))
        x = self.f3(x)
        return x
```

打印模型参数`model.named_parameters()`

```python
model = LeNet()
for name, param in model.named_parameters():
    print(name, param.size())
```

打印模型结构

```python
from torchinfo import summary

print(summary(model, (1, 1, 28, 28)))
```

### 使用Cloud Studio的GPU

PyTorch可以使用简单命令，实现模型训练的GPU加速。[Cloud Studio](https://ide.cloud.tencent.com/)是腾讯云推出的一款云端集成开发环境（IDE），基于浏览器运行，为开发者提供无需本地配置的远程开发体验。

* 通过Web IDE实现远程编码、调试和部署，支持Java、Python、Node.js等多种语言及框架模板。
* 支持GPU运算，可以用于神经网络训练。
* 支持TensorFlow和PyTorch框架。
* 集成VSCode开发环境和AI代码助手。
* 支持主流代码仓库（GitHub、CODING）的云端克隆。

可以使用微信登录账号

<img src="https://raw.githubusercontent.com/hughxusu/lesson-ai/develop/images/cv/Xnip2025-05-02_11-21-06.jpg" style="zoom:40%;" />

选择模板

<img src="https://raw.githubusercontent.com/hughxusu/lesson-ai/develop/images/cv/Xnip2025-05-02_11-26-03.jpg" style="zoom:40%;" />

选择以创建过的应用

<img src="https://raw.githubusercontent.com/hughxusu/lesson-ai/develop/images/cv/Xnip2025-05-02_11-29-58.jpg" style="zoom:40%;" />

进入开发

<img src="https://raw.githubusercontent.com/hughxusu/lesson-ai/develop/images/cv/Xnip2025-05-02_11-33-06.jpg" style="zoom:40%;" />

代码编辑机器类似于VSCode

<img src="https://raw.githubusercontent.com/hughxusu/lesson-ai/develop/images/cv/Xnip2025-05-02_11-38-02.jpg" style="zoom:40%;" />

查看GPU配置

```python
if torch.cuda.is_available():
    gpu_count = torch.cuda.device_count()
    print(f"可用的GPU数量: {gpu_count}")

    for i in range(gpu_count):
        gpu_name = torch.cuda.get_device_name(i)
        print(f"GPU {i}: {gpu_name}")
else:
    print("没有可用的GPU")
```

### 模型训练

模型的训练过程的模式都是相同的，为了简化模型训练过程，模型训练使用[skorch](https://github.com/skorch-dev/skorch)库。skorch库可以模仿sklearn的模式训练，PyTorch模型，安装库

```shell
pip install skorch
```

在skorch使用[`NeuralNet`](https://skorch.readthedocs.io/en/latest/net.html#skorch.net.NeuralNet)及其两个子类[NeuralNetClassifier](https://skorch.readthedocs.io/en/latest/classifier.html#skorch.classifier.NeuralNetClassifier)（分类模型训练）和[NeuralNetRegressor](https://skorch.readthedocs.io/en/latest/regressor.html#skorch.regressor.NeuralNetRegressor)（回归模型训练）封装模型训练过程。

```python
from skorch import NeuralNetClassifier
from skorch.helper import predefined_split

net = NeuralNetClassifier(
    LeNet,
    criterion=nn.CrossEntropyLoss,
    max_epochs=10,
    optimizer=torch.optim.Adam,
    batch_size=1024,
    lr=0.005,
    train_split=predefined_split(valid),
    classes=list(range(10)),
    device='cuda' if torch.cuda.is_available() else 'cpu'
)

net.fit(X=train, y=None)
```

* 使用NeuralNetClassifier封装了LeNet训练过程。
* 第一个参数`module`可以选择传入对象或类，传输类训练过程中skorch会自动创建实例。
* `criterion`为损失函数，需要显示指定。
* `optimizer`选择优化器，默认是SGD优化器。现在一般选用`Adam`优化器。
* `max_epochs`最大轮数；`batch_size`批次数量；`lr`学习率；
* `device='cuda' if torch.cuda.is_available() else 'cpu'`如果有GPU设备使用GPU，否则使用CPU。
* `train_split=predefined_split(valid)`指定验证集，skorch内部自动将PyTorch的`Dataset`数据类型自动封装成`DataLoader`，所以这里只需要传入`Dataset`数据类型，不需要对其封装。
* `net.fit(X=train, y=None)`训练模型，传入训练数据`train`，`Dataset`数据类型包含标签，所以`y=None`
* `classes`传入类别列表，由于`y=None`所以skorch不能推估数据有多少类别，该参数需要手动传入。

绘制损失函数曲线可得

```python
import matplotlib.pyplot as plt

fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))

ax1.plot(net.history[:, 'train_loss'], label='Train Loss', linewidth=3)
ax1.plot(net.history[:, 'valid_loss'], label='Valid Loss', linewidth=3)
ax1.set_xlabel('Epoch', fontsize=14)
ax1.set_ylabel('Loss', fontsize=14)
ax1.set_title('Training & Validation Loss', fontsize=16)
plt.xticks(fontsize=14)
plt.yticks(fontsize=14)
ax1.legend()

ax2.plot(net.history[:, 'valid_acc'], label='Valid Accuracy', linewidth=3)
ax2.set_xlabel('Epoch', fontsize=14)
ax2.set_ylabel('Accuracy (%)', fontsize=14)
ax2.set_title('Validation Accuracy', fontsize=16)
plt.xticks(fontsize=14)
plt.yticks(fontsize=14)
ax2.legend()

plt.tight_layout() 
plt.show()
```

统计测试集的准确率

```python
from sklearn.metrics import accuracy_score

y_pred = net.predict(test) 
y_true = test.targets     
test_accuracy = accuracy_score(y_true, y_pred)
print(f"Test Accuracy: {test_accuracy:.4f}")
```

### 训练过程的优化

`NeuralNet`及其子类中的`callbacks`参数可以实现对训练过程的精细化控制。

1. 增加[`ProgressBar`](https://skorch.readthedocs.io/en/latest/callbacks.html#skorch.callbacks.ProgressBar)显示每个epoch的进度条。注意进度条的工具，需要安装jupyterlab插件`pip install ipywidgets`。

```python
bar = ProgressBar()
```

2. 增加退火函数[LRScheduler](https://skorch.readthedocs.io/en/latest/callbacks.html#skorch.callbacks.LRScheduler)。退火函数（Annealing）主要用于动态调整学习率，以优化模型训练过程。退火函数的优势有

   * 逃离局部最优：通过动态调整学习率，帮助模型跳出局部最小值，寻找全局最优解。
   * 加速收敛：初期使用较大学习率快速下降，后期减小学习率精细调参。
   * 稳定训练：避免后期因学习率过大导致损失震荡。

   常见的退火函数有：固定步长衰减、指数衰减、余弦退火、线性衰减。训练过程中可以首选余弦退火，余弦退火的特点是过度平滑

<img src="https://raw.githubusercontent.com/hughxusu/lesson-ai/develop/images/cv/Xnip2025-02-14_16-25-37.jpg" style="zoom:70%;" />

```python
lr_scheduler = LRScheduler(policy=CosineAnnealingLR, T_max=epochs)
```

* `T_max`一般表示训练的最大轮数，余弦退火会根据最大轮数计算学习率下降曲线。

3. 增加早停函数[EarlyStopping](https://skorch.readthedocs.io/en/latest/callbacks.html#skorch.callbacks.EarlyStopping)，当分数没有提高时回调停止训练，避免过拟合。

```python
early_stopping = EarlyStopping(monitor='valid_acc', lower_is_better=False, patience=6)
```

* `lower_is_better=False`表示监控的指标越大越好；`lower_is_better=True``表示监控的指标越小越好。

4. 默认的训练过程没有记录训练集准确率，为了观察模型是否过拟合，使用[EpochScoring](https://skorch.readthedocs.io/en/latest/callbacks.html#skorch.callbacks.EpochScoring)记录测试集准确率。

```python
train_acc = EpochScoring(
    name='train_acc', scoring='accuracy', 
    on_train=True, lower_is_better=False
)
```

5. 训练后期模型参数可能退化，使用[`Checkpoint`](https://skorch.readthedocs.io/en/latest/callbacks.html#skorch.callbacks.Checkpoint)保存验证集准确率最高的那次的模型。

```python
check_point = Checkpoint(
    dirname='./data/checkpoints', f_params='best_model.pt', 
    monitor='valid_acc_best', load_best=True
)
```

* `dirname`模型保存的路径； `f_params`模型保存文件。
* `monitor`监控的指标；`load_best`训练完成后加载效果最好的模型。

使用上述`callbacks`优化训练过程

```python
from skorch import NeuralNetClassifier
from skorch.callbacks import EarlyStopping, Checkpoint, EpochScoring, LRScheduler, ProgressBar
from torch.optim.lr_scheduler import CosineAnnealingLR

epochs = 70
bar = ProgressBar()
lr_scheduler = LRScheduler(policy=CosineAnnealingLR, T_max=epochs)
early_stopping = EarlyStopping(monitor='valid_acc', lower_is_better=False, patience=6)
train_acc = EpochScoring(name='train_acc', scoring='accuracy', on_train=True)
check_point = Checkpoint(
    dirname='./data/checkpoints', f_params='best_model.pt', 
    monitor='valid_acc_best', load_best=True
)
callbacks = [bar, lr_scheduler, early_stopping, train_acc, check_point]

net = NeuralNetClassifier(
    LeNet,
    criterion=nn.CrossEntropyLoss,
    optimizer=torch.optim.Adam,
    lr=0.005,
    batch_size=1024,
    max_epochs=epochs,
    train_split=predefined_split(valid),
    classes=list(range(10)),
    device='cuda' if torch.cuda.is_available() else 'cpu',
    callbacks=callbacks
)
net.fit(X=train, y=None)
```

*  `lr=0.01`学习率从0.01开始逐渐减小，可以增加初始下降速度。
* `max_epochs=100`最大训练100个epoch，当`valid_acc`不在增加时，训练过程会自动暂停。

绘制准确准确率曲线和损失曲线

```python
fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))

ax1.plot(net.history[:, 'train_loss'], label='Train Loss', linewidth=3)
ax1.plot(net.history[:, 'valid_loss'], label='Valid Loss', linewidth=3)
ax1.set_xlabel('Epoch', fontsize=14)
ax1.set_ylabel('Loss', fontsize=14)
ax1.set_title('Training & Validation Loss', fontsize=16)
plt.xticks(fontsize=14)
plt.yticks(fontsize=14)
ax1.legend()

ax2.plot(net.history[:, 'train_acc'], label='Train Accuracy', linewidth=3)
ax2.plot(net.history[:, 'valid_acc'], label='Valid Accuracy', linewidth=3)
ax2.set_xlabel('Epoch', fontsize=14)
ax2.set_ylabel('Accuracy (%)', fontsize=14)
ax2.set_title('Validation Accuracy', fontsize=16)
plt.xticks(fontsize=14)
plt.yticks(fontsize=14)
ax2.legend()

plt.tight_layout() 
plt.show()
```

打印测试集准确率

```python
y_pred = net.predict(test) 
y_true = test.targets     
test_accuracy = accuracy_score(y_true, y_pred)
print(f"Test Accuracy: {test_accuracy:.4f}")
```

绘制混淆矩阵

```python
from sklearn.metrics import confusion_matrix
import seaborn as sns

cm = confusion_matrix(y_true, y_pred)
print("Confusion Matrix:\n", cm)
plt.figure(figsize=(12, 10))
sns.heatmap(
    cm, 
    annot=True, 
    fmt="d", 
    cmap="Blues",
    annot_kws={"size": 10},
)
plt.xlabel("Predicted Label", fontsize=14)
plt.ylabel("True Label", fontsize=14)
plt.title("Confusion Matrix (Test Set)", fontsize=16)
plt.xticks(fontsize=14)
plt.yticks(fontsize=14)
plt.show()
```

统计测试集中的错误样本

```python
import numpy as np

y_true = np.asarray(test.targets)          
y_pred = net.predict(test)                 
y_prob = net.predict_proba(test)          
wrong_idx = np.where(y_pred != y_true)[0]
error_list = []
for i in wrong_idx:
    features, _ = test[i]                  
    error_list.append({
        "features": features,              
        "true_label": int(y_true[i]),
        "pred_label": int(y_pred[i]),
        "probabilities": y_prob[i]      
    })

print(len(error_list)) 
```

> [!attention]
>
> 针对小数据集可以使用上面的方法，大数据集有可能内存溢出，需要分批次预测。

使用PyTorch模型加载权重参数，测试模型预测结果

```python
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
checkpoint = torch.load('./data/checkpoints/best_model.pt', map_location=device)
loader = DataLoader(test, batch_size=1024, shuffle=False)

load_model = LeNet()
load_model.to(device)
load_model.load_state_dict(checkpoint)
load_model.eval()

all_preds = []     
all_probs = []     
all_labels = []    
with torch.no_grad():             
    for x, y in loader:                  
        x = x.to(device, non_blocking=True)
        y = y.to(device, non_blocking=True)

        logits = load_model(x)                
        probs = logits.softmax(dim=1)   
        preds = probs.argmax(1)         

        all_probs.append(probs.cpu())
        all_preds.append(preds.cpu())
        all_labels.append(y.cpu())

all_probs = torch.cat(all_probs)         
all_preds = torch.cat(all_preds)         
all_labels = torch.cat(all_labels)
probs_np = all_probs.numpy()
max_probs = probs_np.max(axis=1)
preds_np = all_preds.numpy()
labels_np = all_labels.numpy()

print(f'max_probs:  {max_probs[:5]}')
print(f'preds:  {preds_np[:5]}')
print(f'labels: {labels_np[:5]}')
```

### CNN网络的可视化

绘制卷积层的图像代码如下

```python
import torch
import matplotlib.pyplot as plt
from torchvision.utils import make_grid

w1 = load_model.c1.weight.data.clone().cpu()          
grid1 = make_grid(w1, nrow=6, normalize=True, padding=1)  

plt.figure(figsize=(14, 4))
plt.imshow(grid1.permute(1, 2, 0))  
plt.axis('off')
plt.title("LeNet Conv1 Filters", fontsize=16)
plt.show()

w2 = load_model.c2.weight.data.clone().cpu()[:, 0, :, :].unsqueeze(1)  
grid2 = make_grid(w2, nrow=4, normalize=True, padding=1)              

plt.figure(figsize=(10, 10))
plt.imshow(grid2.permute(1, 2, 0))
plt.axis('off')
plt.title("LeNet Conv2 Filters", fontsize=16)
plt.show()

```

学习前的滤波器是随机进行初始化的，所以在滤波器图像没有规律可循，但学习后的滤波器变成了有规律的图像。通过学习，滤波器被更新成了有规律的滤波器，比如从白到黑渐变的滤波器、含有块状区域（称为 blob）的滤波器等。这些滤波器在观察边缘和斑块（局部的块状区域）等

<img src="https://raw.githubusercontent.com/hughxusu/lesson-ai/develop/images/nn/Xnip2025-01-27_16-59-51.jpg" style="zoom:35%;" />

卷积层的滤波器会提取边缘或斑块等原始信息。



