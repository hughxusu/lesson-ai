# 图像分类简介

图像分类就是从给定的类别集合中，为图像分配对应标签的任务。即分析一个输入图像，并返回一个该图像类别的标签。假定类别集为$\text{categories} = \{\text{dog}, \text{cat}\}$，输入一张图片

<img src="https://raw.githubusercontent.com/hughxusu/lesson-ai/develop/images/cv/labradoodle-dog-stick-running-grass.jpg" style="zoom: 35%;" />

模型对图片的分类结果$\text{dog}=95\%$和$\text{cat}=5\%$，根据概率的大小图片为dog类，从而完成分类任务。

## 常用数据集

### Fashion-MNIST

Fashion-MNIST是一个替代MNIST手写数字集的图像数据集。 它是由Zalando（一家德国的时尚科技公司）旗下的研究部门提供。其涵盖了来自10种类别的共7万个不同商品的正面图片。Fashion-MNIST的大小、格式和训练集/测试集划分与原始的MNIST完全一致。训练测试数据划分为60000/10000，28x28的灰度图片。

使用PyTorch下载该数据集

```python
from torchvision import datasets, transforms

full = datasets.FashionMNIST(
    root='./data',train=True, download=True, transform=transforms.ToTensor()
)

test = datasets.FashionMNIST(
    root='./data', train=False, download=True, transform=transforms.ToTensor()
)
print(len(full), len(test))
```

打印数据集信息

```python
image, label = full[0]
print(image.shape)
print(image.max().item())
print(label)
```

绘制示例图像

```python
import matplotlib.pyplot as plt

plt.figure(figsize=(8, 8))
for i in range(9):
    image, label = full[i]
    image = image[0, :, :]
    plt.subplot(3, 3, i+1)
    plt.imshow(image, cmap='gray', interpolation='none')
    plt.title(f"{full.classes[label]}", fontsize=16)

plt.tight_layout()
plt.show()
```

### CIFAR数据集

CIFAR数据集分为CIFAR-10和CIFAR-100两类数据

* CIFAR-10数据集5万张训练图像、1万张测试图像、10个类别、每个类别有6k个图像，图像大小32×32×3。

![](https://raw.githubusercontent.com/hughxusu/lesson-ai/develop/images/cv/4fdf2b82-2bc3-4f97-ba51-400322b228b1.png)

* CIFAR-100数据集也是有5万张训练图像、1万张测试图像、包含100个类别、图像大小32×32×3。

PyTorch中可以直接加载该数据集

```python
from torchvision import datasets

full = datasets.CIFAR10(
    root="./data", train=True, download=True, transform=transforms.ToTensor()
)
test = datasets.CIFAR10(
    root="./data", train=False, download=True, transform=transforms.ToTensor()
)
print(len(full), len(test))
```

打印数据集信息

```python
image, label = full[0]
print(image.shape)
print(image.max().item())
print(label)
```

绘制示例图像

```python
import matplotlib.pyplot as plt

plt.figure(figsize=(8, 8))
for i in range(9):
    image, label = full[i]
    image = image.permute(1, 2, 0)
    plt.subplot(3, 3, i+1)
    plt.imshow(image, interpolation='none')
    plt.title(f"{full.classes[label]}", fontsize=16)

plt.tight_layout()
plt.show()
```

* CIFAR数据是3通道图像，绘制图像前需要对图像通道进行置换`image.permute(1, 2, 0)`

### ImageNet数据集

ImageNet数据集是ILSVRC竞赛使用的是数据集，由斯坦福大学李飞飞教授主导，包含了超过1400万张全尺寸的有标记图片，大约有22000个类别的数据。ILSVRC全称ImageNet Large-Scale Visual Recognition Challenge，是视觉领域最受追捧也是最具权威的学术竞赛之一，代表了图像领域的最高水平。从2010年开始举办到2017年最后一届，使用ImageNet数据集的一个子集，总共有1000类。

[ImageNet首页](https://www.image-net.org/)

该比赛的获胜者从2012年开始都是使用的深度学习的方法

<img src="https://raw.githubusercontent.com/hughxusu/lesson-ai/develop/images/cv/11162584dd974c4fb4dc73ac03f605e2.png" style="zoom:75%;" />

* 2012年冠军是AlexNet,由于准确率远超传统方法的第二名（top5错误率为15.3%，第二名为26.2%），引起了很大的轰动。自此之后，CNN成为在图像识别分类的核心算法模型，带来了深度学习的大爆发。
* 2013年冠军是ZFNet，结构和AlexNet区别不大，分类效果也差不多。
* 2014年亚军是VGG网络，网络结构十分简单，因此至今VGG-16仍在广泛使用。
* 2014年的冠军网络是GoogLeNet ，核心模块是Inception Module。Inception历经了V1、V2、V3、V4等多个版本的发展，不断趋于完善。
* 2015年冠军网络是ResNet。核心是带短连接的残差模块，其中主路径有两层卷积核（Res34），短连接把模块的输入信息直接和经过两次卷积之后的信息融合，相当于加了一个恒等变换。短连接是深度学习又一重要思想，除计算机视觉外，短连接思想也被用到了机器翻译、语音识别/合成领域
* 2017年冠军SENet是一个模块（360公司的模型），可以和其他的网络架构结合，比如GoogLeNet、ResNet等。

上述图像分类模型都比较经典，特别是VGG16、GoogLeNet和ResNet，现在仍然在广泛使用。

## `datasets`的处理

使用PyTorch的datasets导入的图像数据集默认是`PIL.Image.Image`数据类型，像素值在$(0,255)$之间。需要设置`transform=transforms.ToTensor()`可以变为PyTorch的`tensor`数据类型，像素值归一化到$(0,1)$之间。

```python
full = datasets.FashionMNIST(root='./data', train=True, download=True)
test = datasets.FashionMNIST(root='./data', train=False, download=True)
print(len(full), len(test))
print(type(full), full[0])
```

封装一个切分训练集和验证集的函数

```python
from torch.utils.data import random_split

def train_val_split(full, valid_size=10000):
    train_size = len(full) - valid_size
    train, valid = random_split(
        full, [train_size , valid_size],
        generator=torch.Generator().manual_seed(42)
    )

    return train, valid

train, valid = train_val_split(full)
print(len(train), len(valid))
```

在后面的学习过程中，需要对训练数据和测试数据进行不同的处理，封装一个自定义数据集，用于图像变换

```python
from torch.utils.data import Dataset

class PackDataset(Dataset):
    def __init__(self, dataset, transform=None):
        self.dataset = dataset
        self.transform = transform

    def __len__(self):
        return len(self.dataset)

    def __getitem__(self, idx):
        image, label = self.dataset[idx]
        if self.transform:
            image = self.transform(image)
        return image, label

train = PackDataset(train, transform=transforms.Compose([transforms.ToTensor()]))
valid = PackDataset(valid, transform=transforms.Compose([
    transforms.ToTensor(), transforms.Resize(size=227)
]))

img1, _ = train[0]
img2, _ = valid[0]
print(img1.shape, type(img1))
print(img2.shape, type(img2))
```

* `transforms.Compose`工具可以串联多种图像变换的方式，用于模型训练的图像增强。

使用Pillow工具显示，图像的真实大小

```python
import torch
from PIL import Image
import numpy as np
from IPython.display import display

def show_tensor_image(tensor):
    if not isinstance(tensor, torch.Tensor):
        raise TypeError("输入必须是torch.Tensor类型")

    if tensor.dim() != 3:
        raise ValueError("输入Tensor必须是3维的 [C, H, W]")

    channels = tensor.shape[0]
    if channels not in [1, 3]:
        raise ValueError("通道数必须是1（灰度）或3（RGB）")

    if channels == 1:
        img = tensor.squeeze(0)
        img = img.numpy()
        img = (img * 255).astype(np.uint8)
        mode = 'L'
    else:
        img = tensor.permute(1, 2, 0).numpy()
        img = (img * 255).astype(np.uint8)
        mode = 'RGB'

    pil_img = Image.fromarray(img, mode=mode)
    display(pil_img)
```

显示原始数据集大小

```python
show_tensor_image(img1)
```

显示放大后的数据集大小

```python
show_tensor_image(img2)
```

## 模型的平均标准

| 任务类型                 | 合理泛化差距（训练-验证） | 说明                                     |
| :----------------------- | :------------------------ | :--------------------------------------- |
| 简单任务（如MNIST）      | < 2%                      | 数据简单，模型容易拟合，差距应非常小     |
| 中等任务（如CIFAR-10）   | 2% - 5%                   | 数据复杂度中等，允许一定差距             |
| 复杂任务（如ImageNet）   | 5% - 10%                  | 数据复杂，模型容量大，差距可能较大       |
| 高噪声任务（如医学图像） | 10% - 15%                 | 数据噪声大，标签可能不准确，允许较大差距 |
