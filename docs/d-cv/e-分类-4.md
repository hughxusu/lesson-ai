# 残差网络与模型微调

## GoogLeNet

GoogLeNet在加深度的同时做了结构上的创新，引入了一个叫做Inception的结构来代替之前的卷积加激活的经典组件。GoogLeNet在ImageNet分类比赛上的Top-5错误率降低到了6.7%。

<img src="https://raw.githubusercontent.com/hughxusu/lesson-ai/develop/images/cv/1f2229e9e94fe17681cf755e74485050.png" style="zoom:60%;" />

相关论文：[Going Deeper with Convolutions](https://arxiv.org/pdf/1409.4842)

### Inception结构

GoogLeNet中的基础卷积块叫作Inception块，结构如下

<img src="https://raw.githubusercontent.com/hughxusu/lesson-ai/develop/images/cv/fc86defb385e25d5f3948bf08861aaf4.png" style="zoom:70%;" />

Inception块里有4条并行的线路。最后，将每条线路的输出在通道维上连结，并向后进行传输。其中，$1\times1$的卷积，没有考虑在特征图局部信息之间的关系，它的作用主要是：

* 实现跨通道的交互和信息整合。
* 卷积核通道数的降维和升维，减少网络参数。
* $1\times1$卷积核后通常跟随激活函数，因此它不仅是一个线性变换，还引入了非线性，增强了模型的表达能力。

<img src="https://raw.githubusercontent.com/hughxusu/lesson-ai/develop/images/cv/db8ab22bff7282ebe72e11d7d9d0db63.png" style="zoom:70%;" />

1. 直接使用$3\times3$卷积参数量：$3\times3\times192\times32=55296$
2. 使用$1\times1$卷积核，再使用$3\times3$，计算公式：$1\times1\times192\times32+3\times3\times32\times32=15360$

定义Inception块如下

```python
class Inception(nn.Module):
    def __init__(self, in_channels, ch1x1, ch3x3red, ch3x3, ch5x5red, ch5x5, pool_proj):
        super().__init__()
        self.branch1 = conv_block(in_channels, ch1x1, conv_size=1)
        
        self.branch2 = nn.Sequential(
            conv_block(in_channels, ch3x3red, conv_size=1),
            conv_block(ch3x3red, ch3x3, conv_size=3, padding=1)
        )
        
        self.branch3 = nn.Sequential(
            conv_block(in_channels, ch5x5red, conv_size=1),
            conv_block(ch5x5red, ch5x5, conv_size=5, padding=2)
        )
        
        self.branch4 = nn.Sequential(
            nn.MaxPool2d(kernel_size=3, stride=1, padding=1),
            conv_block(in_channels, pool_proj, conv_size=1)
        )

    def forward(self, x):
        branch1 = self.branch1(x)
        branch2 = self.branch2(x)
        branch3 = self.branch3(x)
        branch4 = self.branch4(x)
        return torch.cat([branch1, branch2, branch3, branch4], 1)
```

### 网络构建

[GoogLeNet 结构图](https://production-media.paperswithcode.com/methods/Screen_Shot_2020-06-22_at_3.28.59_PM.png)

各个网络层参数

![](https://raw.githubusercontent.com/hughxusu/lesson-ai/develop/images/cv/googlenet-params.png)

1. B1模块

```python
self.conv_pool1 = conv_pool_block(3, 64, 7, 2, 3, 3, 2, 1)
```

2. B2模块

```python
self.conv2 = conv_block(64, 64, conv_size=1)
self.conv_pool2 = conv_pool_block(64, 192, 3, 1, 1, 3, 2, 1)
```

3. B3模块

```python
self.inception3a = Inception(192, 64, 96, 128, 16, 32, 32)
self.inception3b = Inception(256, 128, 128, 192, 32, 96, 64)
self.maxpool3 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)
```

4. B4模块

```python
self.inception4a = Inception(480, 192, 96, 208, 16, 48, 64)
self.aux1 = self._auxiliary_classifier(512, self.categories)
self.inception4b = Inception(512, 160, 112, 224, 24, 64, 64)
self.inception4c = Inception(512, 128, 128, 256, 24, 64, 64)
self.inception4d = Inception(512, 112, 144, 288, 32, 64, 64)
self.aux2 = self._auxiliary_classifier(832, self.categories)
self.inception4e = Inception(528, 256, 160, 320, 32, 128, 128)
self.maxpool4 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)
```

5. 输出模块

GoogLeNet使用全局平均池化层，来替代Flatten。将特征图每一通道中所有像素值相加后求平均，得到就是GAP的结果，在将其送入后续网络中进行计算。

<img src="https://raw.githubusercontent.com/hughxusu/lesson-ai/develop/images/cv/bc07bc99154507d1f4e1a009e32a7991.png" style="zoom:60%;" />

```python
self.inception5a = Inception(832, 256, 160, 320, 32, 128, 128)
self.inception5b = Inception(832, 384, 192, 384, 48, 128, 128)
self.avgpool = nn.AdaptiveAvgPool2d((1, 1))
self.dropout = nn.Dropout(0.4)
self.fc = nn.Linear(1024, self.categories)
```

整体网络类

```python
class GoogleNet(ConfigModule):
    def __init__(self, model_config='config.yaml'):
        super().__init__(model_config)
        self.conv_pool1 = conv_pool_block(3, 64, 7, 2, 3, 3, 2, 1)
        self.conv2 = conv_block(64, 64, conv_size=1)
        self.conv_pool2 = conv_pool_block(64, 192, 3, 1, 1, 3, 2, 1)
        
        self.inception3a = Inception(192, 64, 96, 128, 16, 32, 32)
        self.inception3b = Inception(256, 128, 128, 192, 32, 96, 64)
        self.maxpool3 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)
        
        self.inception4a = Inception(480, 192, 96, 208, 16, 48, 64)
        self.aux1 = self._auxiliary_classifier(512, self.categories)
        self.inception4b = Inception(512, 160, 112, 224, 24, 64, 64)
        self.inception4c = Inception(512, 128, 128, 256, 24, 64, 64)
        self.inception4d = Inception(512, 112, 144, 288, 32, 64, 64)
        self.aux2 = self._auxiliary_classifier(832, self.categories)
        self.inception4e = Inception(528, 256, 160, 320, 32, 128, 128)
        self.maxpool4 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)
        
        self.inception5a = Inception(832, 256, 160, 320, 32, 128, 128)
        self.inception5b = Inception(832, 384, 192, 384, 48, 128, 128)
        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))
        self.dropout = nn.Dropout(0.4)
        self.fc = nn.Linear(1024, self.categories)

    @staticmethod
    def _auxiliary_classifier(in_channels, num_classes):
        return nn.Sequential(
            nn.AvgPool2d(kernel_size=5, stride=3, padding=2),
            conv_block(in_channels, 128, conv_size=1),
            nn.Flatten(),
            dense_block(128, 1024, 0.7),
            nn.Linear(1024, num_classes)
        )

    def forward(self, x):
        x = self.conv_pool1(x)
        x = self.conv_pool2(self.conv2(x))
        
        x = self.inception3b(self.inception3a(x))
        x = self.maxpool3(x)

        x = self.inception4a(x)
        aux1 = self.aux1(x)

        x = self.inception4e(self.inception4d(self.inception4c(self.inception4b(x))))
        aux2 = self.aux2(x)
        x = self.maxpool4(x)

        x = self.inception5b(self.inception5a(x))
        x = nn.Flatten()(self.avgpool(x))
        x = self.dropout(x)
        x = self.fc(x)
        return x, aux1, aux2

    def _calculate(self, x, y):
        y_hat, aux1, aux2 = self(x)
        loss = self.loss_fn(y_hat, y) + self.loss_fn(aux1, y) * 0.3 + self.loss_fn(aux2, y) * 0.3
        return y_hat, loss
```

### 训练模型

训练模型

```python
trainer = pl.Trainer(
    max_epochs=100,
    accelerator="auto",
    devices="auto",
    deterministic=True
)
data = CIFAR10Data()
trainer.fit(google, datamodule=data)
```

打印评测结果

```python
trainer.test(google, datamodule=data)
```

绘制学习曲线

```python
from utils.plot import TrainingCurve
drawing = TrainingCurve('./lightning_logs/version_0/')
drawing.plot()
```

### Inception结构的改进

GoogLeNet是以InceptionV1为基础进行构建的，所以GoogLeNet也叫做InceptionNet，在随后的⼏年⾥，研究⼈员对GoogLeNet进⾏了数次改进， 就又产生了InceptionV2、V3、V4等版本。

1. InceptionV2。大卷积核拆分为小卷积核，将V1中的5x5的卷积用两个3x3的卷积替代，从而增加网络的深度，减少了参数。

<img src="https://raw.githubusercontent.com/hughxusu/lesson-ai/develop/images/cv/3c4a8fb6fe0839919d8f551bd7823440.png" style="zoom:45%;" />

2. InceptionV3。将n×n卷积分割为1×n和n×1两个卷积。

<img src="https://raw.githubusercontent.com/hughxusu/lesson-ai/develop/images/cv/6b59ec36f19062c0ea341887a99186be.png" style="zoom:50%;" />

## 残差网络

网络越深，获取的信息就越多，特征也越丰富。但是在实践中，随着网络的加深，优化效果反而越差，测试数据和训练数据的准确率反而降低了。

<img src="https://raw.githubusercontent.com/hughxusu/lesson-ai/develop/images/cv/8d17d4ed997300dad29d868b16039850.png" style="zoom:90%;" />

针对这一问题，何恺明等人提出了残差网络残差网络（ResNet）在2015年的ImageNet图像识别挑战赛夺魁，并深刻影响了后来的深度神经网络的设计。

<img src="https://raw.githubusercontent.com/hughxusu/lesson-ai/develop/images/cv/08803e5a9b2d589cc873657fd0903fef.png" style="zoom:60%;" />

相关论文：[Deep Residual Learning for Image Recognition](https://arxiv.org/pdf/1512.03385)

### 残差层的原理

<img src="https://raw.githubusercontent.com/hughxusu/lesson-ai/develop/images/cv/4513e8ffd7dd54db4ff54d3c3a542c6c.png" style="zoom:60%;" />

假设卷入层是输入是$X$，训练神经网络的过程是找到一个理想的输出$H(X)$

* 理想的输入$H(X)$表示一种理想的特征图，以最优的方式满足后面网络的需要。
* 理想的特征图最差的情况应该与$X$性能一致，不应该比$X$性能还差。

$F(x)$表示$X$经过网后实际输出的特征图。

> [!note]
>
> 深度神经网络训练的挑战，退化问题（Addressing Degradation Problem）。
>
> 在深度神经网络中，随着网络深度的增加，理论上模型的能力应该增强，可以学习更复杂的特征。然而，实际情况是当网络深度增加到一定程度后，模型的性能不仅没有提升，反而开始下降，这种现象被称为退化问题 。退化问题不是过拟合引起的，退化问题指的是，即使在训练集上，更深的网络也比更浅的网络表现更差。 这意味着更深的网络训练过程，遇到了困难。

#### 恒等映射（Identity Mapping）的重要性

最差的情况下，深层网络性能至少和浅层网络一样。假设在一个浅层网络基础上增加了一些层，最差的情况是新增的这些层不影响网络的性能。换句话说，新增的层最差，也应该学习到恒等映射，即输入什么就输出什么，不引入任何额外的变换。

> [!warning]
>
> 如果新增的层能够学习到恒等映射，那么深层网络至少不会比浅层网络更差。  如果新增的层还能学习到有效的特征变换，那么深层网络就应该比浅层网络更好。

#### 残差块（Residual Block）的设计

在普通的网络层中，学习目标是希望拟合出理想的输出$H(X)$。而在残差块中，改变了思路，让网络去学习残差函数$F(X) = H(X) - X$。 也就是说，学习目标是输出$H(X)$ 和输入$X$之间的差异（residual）。假设网络学习到了理想残差函数$F'(X)$，最终的输出应该加上原始的输入，即$H(X) = F'(X) + X$。所以，实际输出就变为$F(X)+X$。 

举个例子，假设要把一张略微模糊的猫的图片变得清晰（图像超分辨率任务）。

- 直接学习$H(X)$：让网络直接学习一个映射$H(X)$来输出清晰的猫的图片，网络需要从模糊的输入$X$中学习到清晰猫图片的所有特征，包括猫的轮廓、纹理、细节等等。
- 学习残差$F(X) = H(X) - X$：让网络学习模糊图像$X$和清晰图像$H(X)$之间的差异。  这个差异可能主要集中在图像的高频细节信息（例如，边缘更锐利，纹理更清晰）。网络只需要学习如何添加这些高频细节到模糊图像$X$上，就可以得到清晰的图像$H(X) = F(X) + X$。这显然比直接学习完整的清晰图像$H(X)$要更容易。

> [!warning]
>
> 这里的加法指的是元素级别的加法，将F(x)和原始输入的特征图对应元素相加。
>
> ```
> A =                B =                    C =
>  [[1, 2, 3],        [[10, 11, 12],         [[1+10, 2+11, 3+12],
>   [4, 5, 6],         [13, 14, 15],          [4+13, 5+14, 6+15],
>   [7, 8, 9]]         [16, 17, 18]]          [7+16, 8+17, 9+18]]
> ```

#### 学习残差的好处

如果希望网络层学习到恒等映射$H(X) = X$，那么网络层的权重需要精心调整，使得输出尽可能接近输入。  这对于深层网络来说是非常困难的，优化器很难找到合适的参数组合来精确地学习恒等映射。

在残差块中，如果理想的映射$H(X)$就是恒等映射，那么最优的情况就是让$F(X)$逼近于0。  将$F(X)$逼近于0，只需要让残差块中的卷积层权重趋近于零即可。

> [!warning]
>
> 残差模块学习恒等映射比，一般网络更容易。

#### 残差模块的优点

* 解决退化问题。通过残差连接，即使深层网络中的某些层学习效果不佳，学习到的$F(x)$趋近于0，信息仍然可以通过shortcut连接无损地传递到后面的层。 这样就避免了信息在深层网络中逐渐衰减，缓解了退化问题。即使网络深度增加，性能也不会急剧下降，反而有可能因为更深的网络层能够学习到更复杂的特征而提升性能。

- 减缓梯度消失。残差连接提供了一条直接的梯度通路（gradient highway），梯度可以直接从深层传递到浅层，而无需完全依赖于中间层。
- 学习”差异“或”变化“。学习残差$F(X) = H(X) - X$ 意味着网络层不是从头开始学习全新的特征映射 $H(X)$，而是学习在输入$X$的基础上需要进行哪些“调整”或“变化”才能得到理想的输出$H(X)$。

### 残差层的设计

残差块有两种设计分别用于浅层网络和深层网络，深层网络中$1\times1$的卷积用于降维。

<img src="https://raw.githubusercontent.com/hughxusu/lesson-ai/develop/images/cv/renet-1.jpg" style="zoom:55%;" />

在残差网络中，残差块的输入$X$ 和残差分支$F(X)$必须有相同的形状，在一些情况下，残差块的输入维度和输出维度可能会发生变化，所以需要在shortcut连接上增加卷积。

<img src="https://raw.githubusercontent.com/hughxusu/lesson-ai/develop/images/cv/resnet-2.jpg" style="zoom:60%;" />

残差块中沿用了VGG的设计，用多层小卷积来代替大的卷积核。

### 残差层的实现

实践证明在残差块中加入BN层效果会更好，浅层残差块设计如下

<img src="https://raw.githubusercontent.com/hughxusu/lesson-ai/develop/images/cv/e7c3b6da09fcc5aea9f514d29eb4deb6.png" style="zoom:65%;" />

残差单元的实现

```python
class ResUnit(nn.Module):
    def __init__(self, in_channels, out_channels, stride=1):
        super().__init__()
        self.conv1 = conv_relu(in_channels, out_channels, conv_step=stride, padding=1)
        self.conv2 = conv_block(out_channels, out_channels, padding=1)
        self.shortcut = nn.Sequential()
        if stride != 1 or in_channels != out_channels:
            self.shortcut = conv_block(in_channels, out_channels, conv_size=1, conv_step=stride)

    def forward(self, x):
        out = self.conv1(x)
        out = self.conv2(out)
        out += self.shortcut(x)
        return nn.ReLU()(out)
```

* `out_channels`残差块的卷积数（模块输出的通道数量），
* 根据`stride`判断是否要添加卷积层，保持模型输入的尺寸一致。

### 残差网络的实现

ResNet的层数主要指残差网络中包含的卷积层数量和全连接层数量，经典的残差网层数有：

* ResNet-18
* ResNet-34
* ResNet-50
* ResNet-101
* ResNet-152

ResNet-18结构图如下

![](https://raw.githubusercontent.com/hughxusu/lesson-ai/develop/images/cv/420d05bfd2718b5870d436f26db2b84d.png)

残差块的实现

```python
def res_block(in_channels, out_channels, num_residuals, stride=2):
    layers = []
    layers.append(ResUnit(in_channels, out_channels, stride))
    for _ in range(num_residuals - 1):
        layers.append(ResUnit(out_channels, out_channels))
    return nn.Sequential(*layers)
```

* `num_residuals`残差块中包含几个残差层。
* `stride`控制卷积的步长。

构建残差网络

```python
class ResNet18(ConfigModule):
    def __init__(self, model_config='config.yaml'):
        super().__init__(model_config)
        self.conv_pool1 = conv_pool(3, 64, 3, 1, 1, 3, 2, 1)
        self.res1 = res_block(64, 64, 2, 1)
        self.res2 = res_block(64, 128, 2)
        self.res3 = res_block(128, 256, 2)
        self.res4 = res_block(256, 512, 2)

        self.avg = nn.AdaptiveAvgPool2d((1, 1))
        self.fc = dense(512, self.categories)

    def forward(self, x):
        x = self.conv_pool1(x)
        x = self.res1(x)
        x = self.res2(x)
        x = self.res3(x)
        x = self.res4(x)
        x = self.avg(x)
        x = nn.Flatten()(x)
        return self.fc(x)
```

打印残差网络信息

```python
device = get_device()
res18 = ResNet18()
res18.to(device)
summary(res18, (3, 32, 32))
```

训练模型

```python
trainer = pl.Trainer(
    max_epochs=100,
    accelerator="auto",
    devices="auto",
    deterministic=True
)
data = CIFAR10Data()
trainer.fit(res18, datamodule=data)
```

测试模型准确率

```python
trainer.test(res18, datamodule=data)
```

打印训练曲线

```python
drawing = TrainingCurve('./lightning_logs/resnet18-100epochs/')
drawing.plot()
```

有论文表示残差网在CIFAR10准确率可以达到94%，[参考文章](https://blog.csdn.net/qq_41019681/article/details/109757387)。













 
