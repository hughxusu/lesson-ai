# 评价分类结果

> [!note]
>
> 一个癌症预测系统，输入体检信息，可以判断是否有癌症，该系统的预测准确率（Accuracy）是$99.9\%$。

如果该癌症的发病率是$0.1\%$。只要系统预测所以人都是健康的，系统的准确率即可达到$99.9\%$；如果该癌症的发病率是$0.01\%$。只要系统预测所以人都是健康的，系统的准确率即可达到$99.99\%$

> [!warning]
>
> 上述情况的数据称为极度偏斜（Skewed Data）。所以分类准确率远远不能表示分类器性能。

## 混淆矩阵

混淆矩阵（Confusion Matrix），对于二分类问题，混淆矩阵如下。

|                            | 预测为$\hat P$       | 预测为$\hat N$       |
| -------------------------- | -------------------- | -------------------- |
| 真实$P$（正样本 Positive） | TP（True Positive）  | FN（False Negative） |
| 真实$N$（负样本 Negative） | FP（False Positive） | TN（True Negative）  |

假设有10000人，其癌症预测结果的混淆矩阵如下

|      | $\hat P$ | $\hat N$ |
| ---- | -------- | -------- |
| $P$  | 8        | 2        |
| $N$  | 12       | 9978     |

## 精确率和召回率

|      | $\hat P$                                                     | $\hat N$ |                                                              |
| ---- | ------------------------------------------------------------ | -------- | ------------------------------------------------------------ |
| $P$  | TP                                                           | FN       | 召回率$\text{Recall} = \frac{\text{TP}}{\text{TP} + \text{FN}}$ |
| $N$  | FP                                                           | TN       |                                                              |
|      | 精确率$\text{Precision} = \frac{\text{TP}}{\text{TP} + \text{FP}}$ |          | 准确率$\text{Accuracy}=\frac{\text{TP+TN}}{\text{ALL}}$      |

1. 通常在有偏数据中将分类为正样本作为关注的对象。
2. 精确率表示预测关注的事件有多准。
3. 召回率表示关注的事件，真实发生后，被成功预测的有多少。

在癌症预测中计算精确率和召回率

|      | $\hat P$                                   | $\hat N$ |                                                |
| ---- | ------------------------------------------ | -------- | ---------------------------------------------- |
| $P$  | 8                                          | 2        | $\text{Recall} = \frac{8}{8 + 2}=80\%$         |
| $N$  | 12                                         | 9978     |                                                |
|      | $\text{Precision} = \frac{8}{12 + 8}=40\%$ |          | $\text{Accuracy}=\frac{8+9978}{10000}=99.86\%$ |

1. 上述预测的精确率表示预测癌症的成功率。
2. 召回率表示癌症患者被成功找到的概率。

<img src="https://raw.githubusercontent.com/hughxusu/lesson-ai/develop/images/base/700px-Precisionrecall.svg.png" style="zoom:65%;" />

对于10000个人，癌症的发病率为$0.1\%$，预测所以人为健康的

|      | $\hat P$                             | $\hat N$ |                                             |
| ---- | ------------------------------------ | -------- | ------------------------------------------- |
| $P$  | 0                                    | 10       | $\text{Recall} = \frac{0}{10 + 0}=0$        |
| $N$  | 0                                    | 9990     |                                             |
|      | $\text{Precision} = \frac{0}{0 + 0}$ |          | $\text{Accuracy}=\frac{9990}{10000}=99.9\%$ |

1. 精确率的计算无意义。
2. 召回率为0。

### sklearn计算精确率和召回率

导入癌症数据集，划分训练集和测试集

```python
from sklearn import datasets
from sklearn.model_selection import train_test_split

cancer = datasets.load_breast_cancer()
print(cancer.target_names)
x = cancer.data
y = cancer.target
x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=42)
```

训练模型并预测

```python
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import Pipeline
from sklearn.linear_model import LogisticRegression

pipeline = Pipeline([
    ('scaler', StandardScaler()),
    ('log_reg', LogisticRegression())
])
pipeline.fit(x_train, y_train)
y_hat = pipeline.predict(x_test)
```

计算混淆矩阵、精确率和召回率，函数均在[`metrics`](https://scikit-learn.org/stable/api/sklearn.metrics.html)包中。

```python
from sklearn.metrics import confusion_matrix, precision_score, recall_score

print(confusion_matrix(y_test, y_hat))
print(precision_score(y_test, y_hat))
print(recall_score(y_test, y_hat))
```

[`classification_report`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html)可以打印评估报告

```python
from sklearn.metrics import classification_report

print(classification_report(
    y_test, y_hat, target_names=cancer.target_names
))
```

### 精确率和召回率的选择

在现实应用中不同的算法精确率和召回率，表现不尽相同：

* 算法一，精确率高，召回率低。
* 算法二，精确率低，召回率高。

> [!note]
>
> 如何选择合适的算法？

算法的选择需要依据实际问题确定。

* 股票涨跌的分类问题。
* 癌症病人的分类问题。

如果需要同时兼顾精确率和召回率，使用评价标准F1-Score。
$$
F_1=\frac{2\cdot\text{Precision}\cdot\text{Recall}}{\text{Precision}+\text{Recall}}
$$
F1-Score本质描述的是精确率和召回率的**调和平均值**。F1-Score的特性是如果精确率和召回率不平衡，F1-Score的计算值会非常低。F1-Score计算

```python
from sklearn.metrics import f1_score

print(f1_score(y_test, y_log_predict))
```

上述的计算结果明显低于准确率的计算结果。

### 精确率和召回率的关系

逻辑回归的数学表示如下
$$
\hat{p}=
\sigma \left( \theta^{T}\cdot x_b \right)=\frac{1}{1+e^{\theta^{T}\cdot x_b}} \qquad
\hat{y}=
\begin{cases}
 1, & \hat{p}\ge 0.5 \Rightarrow \theta^{T}\cdot x_b \ge 0\\
 0, & \hat{p}< 0.5 \Rightarrow \theta^{T}\cdot x_b < 0 \\
\end{cases}
$$
其中$\theta^{T}\cdot x_b=0$为二者的决策边界，假设决策边界的阈值可以修改

$$
\theta^{T}\cdot x_b=\text{threshold}
$$
上述改动相当于给算法引入一个新的超参数threshold，通过修改该参数，可以平移决策边界。从而影响分类结果。

1. 当$\text{threshold}=0$，时精确率和召回率的示意图

<img src="https://raw.githubusercontent.com/hughxusu/lesson-ai/develop/images/base/p-r-1.jpg" style="zoom:55%;" />

2. 当$\text{threshold}>0$，时精确率和召回率的示意图

<img src="https://raw.githubusercontent.com/hughxusu/lesson-ai/develop/images/base/p-r-2.jpg" style="zoom:55%;" />

3. 当$\text{threshold}<0$，时精确率和召回率的示意图

<img src="https://raw.githubusercontent.com/hughxusu/lesson-ai/develop/images/base/p-r-3.jpg" style="zoom:55%;" />

精确率和召回率的变化根据分类阈值变化而变化：

1. 阈值越高精确率越高，召回率越低。
2. 阈值越低精确率越低，召回率越高。

精确率和召回率变化示意图

<img src="https://raw.githubusercontent.com/hughxusu/lesson-ai/develop/images/base/1*KZu3UEBx3UIgOvdS6V_h_A.png" style="zoom:75%;" />

使用程序验证精确率和召回率的变化

sklearn中使用[`decision_function`](https://scikit-learn.org/stable/glossary.html#term-decision_function)用来计算样本到决策边界的有符号距离

* 正值：属于正类（类别1）；负值：属于负类（类别0）。
* 绝对值越大：置信度越高；值为零表示样本正好落在决策边界（超平面）上。

```python
decision_scores = pipeline.decision_function(x_test)
print(decision_scores.shape)
print(decision_scores[:10])
print(np.min(decision_scores))
print(np.max(decision_scores))
```

当$\text{threshold}>0$（$\text{threshold}=5$）时预测的精确率和召回率

```python
import numpy as np

y_hat_2 = np.array(decision_scores >= 5, dtype='int')
print(confusion_matrix(y_test, y_hat_2))
print(precision_score(y_test, y_hat_2))
print(recall_score(y_test, y_hat_2))
```

当$\text{threshold}<0$（$\text{threshold}=-5$）时预测的精确率和召回率

```python
y_hat_3 = np.array(decision_scores >= -5, dtype='int')
print(confusion_matrix(y_test, y_hat_3))
print(precision_score(y_test, y_hat_3))
print(recall_score(y_test, y_hat_3))
```

绘制PR曲线

```python
from sklearn.metrics import precision_recall_curve
import matplotlib.pyplot as plt

precisions, recalls, thresholds = precision_recall_curve(y_test, decision_scores)
plt.figure(figsize=(10, 8))
plt.plot(precisions, recalls, linewidth=2)
plt.xticks(fontsize=16)
plt.yticks(fontsize=16)
plt.show()
```

> [!warning]
>
> 在sk-learn中`thresholds`比`precisions`和`recalls`多一个值。

使用PR曲线可以比较不同模型的性能

<img src="https://raw.githubusercontent.com/hughxusu/lesson-ai/develop/images/base/128711011f4a4e1249040612c72b62d4.jpg" style="zoom:50%;" />

模型B要比模型A好，因为模型B无论是精准率还是召回率都要比模型A的高。

## ROC曲线

ROC曲线是Receiver Operation Characteristic Curve缩写，最早在统计学领域使用。ROC用来描述分类模型的TPR和FPR之间的关系，从而确定分类模型的好坏。

|      | $\hat P$ | $\hat N$ |                                                        | 坐标轴 |
| ---- | -------- | -------- | ------------------------------------------------------ | ------ |
| $P$  | TP       | FN       | $\text{TPR} = \frac{\text{TP}}{\text{TP} + \text{FN}}$ | y轴    |
| $N$  | FP       | TN       | $\text{FPR} = \frac{\text{FP}}{\text{FP} + \text{TN}}$ | x轴    |

* TPR是预测正确的正样本，占**真实正样本**的比例。
* FPR是预测错误的正样本，占**真实负样本**的比例。

|                                       | $P$共A个样本                                         | $N$共B个样本                                         |
| ------------------------------------- | ---------------------------------------------------- | ---------------------------------------------------- |
| $\hat P$                              | a                                                    | b                                                    |
|                                       | $\text{TPR} = \frac{\text{a}}{\text{A}}$             | $\text{FPR} = \frac{\text{b}}{\text{B}}$             |
| 概率阈值为0时，所以样本都预测为正样本 | $a=A \rightarrow \frac{a}{A}=1$<br>预测对的正样本为A | $b=B \rightarrow \frac{b}{B}=1$<br>预测错的正样本为B |
| 概率阈值为1时，所以样本都预测为负样本 | $a=0 \rightarrow \frac{a}{A}=0$<br>预测对的正样本为0 | $b=0 \rightarrow \frac{b}{B}=0$<br>预测错的正样本为0 |

计算下面10个样本的预计结果的ROC曲线

| 样本编号 | 1    | 2    | 3    | 4    | 5    | 6    | 7    | 8    | 9    | 10   |
| -------- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- |
| 真实标签 | 1    | 0    | 1    | 0    | 1    | 0    | 1    | 0    | 1    | 0    |
| 预测概率 | 0.9  | 0.8  | 0.75 | 0.7  | 0.6  | 0.55 | 0.4  | 0.3  | 0.2  | 0.1  |

阈值为1时：所有预测标签均为0，所以TPR和FPR均为0。ROC曲线的计算过程如下

| 阈值 | TP   | FP   | FN   | TN   | TPR  | FPR  |
| ---- | ---- | ---- | ---- | ---- | ---- | ---- |
| 1.0  | 0    | 0    | 5    | 5    | 0.0  | 0.0  |
| 0.9  | 1    | 0    | 4    | 5    | 0.2  | 0.0  |
| 0.8  | 1    | 1    | 4    | 4    | 0.2  | 0.2  |
| 0.75 | 2    | 1    | 3    | 4    | 0.4  | 0.2  |
| 0.7  | 2    | 2    | 3    | 3    | 0.4  | 0.4  |
| 0.6  | 3    | 2    | 2    | 3    | 0.6  | 0.4  |
| 0.55 | 3    | 3    | 2    | 2    | 0.6  | 0.6  |
| 0.4  | 4    | 3    | 1    | 2    | 0.8  | 0.6  |
| 0.3  | 4    | 4    | 1    | 1    | 0.8  | 0.8  |
| 0.2  | 5    | 4    | 0    | 1    | 1.0  | 0.8  |
| 0.1  | 5    | 5    | 0    | 0    | 1.0  | 1.0  |

sklearn中使用`roc_curve`计算ROC曲线的参数，绘制上述样本的ROC曲线

```python
from sklearn.metrics import roc_curve

# 真实标签
y_true = [1, 0, 1, 0, 1, 0, 1, 0, 1, 0]

# 预测概率
y_scores = [0.9, 0.8, 0.75, 0.7, 0.6, 0.55, 0.4, 0.3, 0.2, 0.1]

fpr, tpr, _ = roc_curve(y_true, y_scores)
plt.figure(figsize=(10, 10))
plt.plot(fpr, tpr, marker='o', label='ROC Curve', linewidth=2)
plt.xticks(fontsize=16)
plt.yticks(fontsize=16)
plt.legend(fontsize=16)
plt.grid(True)
plt.show()
```

绘制癌症分类的ROC曲线

```python
from sklearn.metrics import roc_curve

fprs, tprs, thresholds = roc_curve(y_test, decision_scores)
plt.figure(figsize=(10, 8))
plt.plot(fprs, tprs, linewidth=2)
plt.xticks(fontsize=16)
plt.yticks(fontsize=16)
plt.show()
```

通过ROC曲线分析模型性能

<img src="https://raw.githubusercontent.com/hughxusu/lesson-ai/develop/images/base/pF5oo7R.png" style="zoom: 33%;" />

ROC曲线下面的面积称为AUC面积，面积越大分类性能越好。

<img src="https://raw.githubusercontent.com/hughxusu/lesson-ai/develop/images/base/ROC-curves-and-area-under-curve-AUC.png" style="zoom:65%;" />

AUC的最大值是1。[ROC-AUC原理及计算方法](https://rogerspy.github.io/2021/07/29/roc-auc/)

评价标准的比较

| 评价标准       | 问题                                                       |
| -------------- | ---------------------------------------------------------- |
| 准确率         | 1. 容易被样本不均衡性<br />2. 指标被阈值影响               |
| 精确率和召回率 | 1. 每个指标只反映一类预测结果的指标<br />2. 指标被阈值影响 |
| ROC曲线和AUC值 | 用于比较两个模型的性能                                     |

## 多分类问题的混淆矩阵

sklearn的`precision_score`函数中有参数可以实现多分类的精确率计算

```python
iris = datasets.load_iris()
X = iris.data
y = iris.target

X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=95)
log_reg = LogisticRegression()
log_reg.fit(X_train, y_train)
log_reg.score(X_test, y_test)
y_predict = log_reg.predict(X_test)
print(precision_score(y_test, y_predict, average='micro'))
```

混淆矩阵可以用于表示多分类的性能，打印多分类问题的混淆矩阵

```python
print(confusion_matrix(y_test, y_predict))
```

混淆矩阵的可视化

```python
cfm = confusion_matrix(y_test, y_predict)
plt.matshow(cfm, cmap=plt.cm.gray)
plt.xticks(fontsize=16)
plt.yticks(fontsize=16)
plt.show()
```

为了更清楚的看到预测错误的区域可以对混淆矩阵进行如下处理

```python
row_sums = np.sum(cfm, axis=1)
err_matrix = cfm / row_sums
np.fill_diagonal(err_matrix, 0)
print(err_matrix)
plt.matshow(err_matrix, cmap=plt.cm.gray)
plt.xticks(fontsize=16)
plt.yticks(fontsize=16)
plt.show()
```

## 分类不平衡的处理

[imbalanced-learn](https://imbalanced-learn.org/stable/)工具包用于处里数据不平衡问题。安装`pip install imbalanced-learn`

使用[`make_classification`](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_classification.html)生成模拟数据

```python
from sklearn.datasets import make_classification

X, y = make_classification(n_samples=5000, n_features=2, n_classes=3,
                           n_informative=2, n_redundant=0,
                           n_repeated=0,  n_clusters_per_class=1, 
                           weights=[0.01, 0.05, 0.94], random_state=0)
```

使用[`Counter`](https://docs.python.org/zh-cn/3.11/library/collections.html#counter-objects)类统计样本个数

```python
from collections import Counter

Counter(y)
```

绘制数据分布

```python
def plot_distribution(X, y):
    plt.figure(figsize=(10, 8))
    plt.scatter(X[:, 0], X[:, 1], c=y, s=100, cmap='viridis')
    plt.xticks(fontsize=16)
    plt.yticks(fontsize=16)
    plt.show()
    
plot_distribution(X, y)
```

### 过采样法

增加一些少数类样本使得正、反例数目接近。

1. 随机过采样方法：随机复制少数类的样本，将它扩大到与多少类样本数量接近。

```python
from imblearn.over_sampling import RandomOverSampler

ros = RandomOverSampler(random_state=0)
X_resampled, y_resampled = ros.fit_resample(X, y)
Counter(y_resampled)
plot_distribution(X_resampled, y_resampled)
```

容易造成模型的过拟合问题。

2. SMOTE算法（Synthetic Minority Oversampling）合成少数类过采样技术。

<img src="https://raw.githubusercontent.com/hughxusu/lesson-ai/develop/images/base/znxtxb-14-6-shihongbo-1.jpg" style="zoom:30%;" />

```python
from imblearn.over_sampling import SMOTE

X_resampled, y_resampled = SMOTE().fit_resample(X, y)
Counter(y_resampled)
plot_distribution(X_resampled, y_resampled)
```

### 欠采样方法

除一些多数类中的样本使得正例、反例数目接近。随机欠采样方法：随机选择一些多数量样本从训练数据中移除。

```python
from imblearn.under_sampling import RandomUnderSampler

rus = RandomUnderSampler(random_state=0)
X_resampled, y_resampled = rus.fit_resample(X, y)
Counter(y_resampled)
plot_distribution(X_resampled, y_resampled)
```

随机欠采样方法可能会造成重要信息丢失。

