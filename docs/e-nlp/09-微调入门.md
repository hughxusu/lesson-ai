# 模型微调入门

## Hugging Face Datasets

[`Datasets`](https://huggingface.co/docs/datasets/index)是一个用于访问和共享音频、计算机视觉和自然语言处理（NLP）任务数据集的Python库，可以方便加载[Hugging Face上的数据集](https://huggingface.co/datasets)。安装`Datasets`包

```shell
pip install datasets
```

* [如何创建自己的`Datasets`](https://huggingface.co/docs/datasets/create_dataset)
* [上传数据到Hugging Face](https://huggingface.co/docs/datasets/upload_dataset)

> [!warning]
>
> `Datasets`使用生成器创建数据集，得到一个可迭代对象。

### 下载训练数据

[`Yelp/yelp_review_full`](https://huggingface.co/datasets/Yelp/yelp_review_full)数据集包括来自Yelp的评论，该数据集主要用于文本分类。有650,000个训练样本和50,000个测试样本。

```python
from datasets import load_dataset

dataset = load_dataset("Yelp/yelp_review_full", cache_dir="./data/hf/datasets")
print(dataset)
```

* `cache_dir="./data/hf/datasets"`指定文件的下载路径。

打印一条数据

```python
print(dataset["train"][0])
```

随机显示10条数据

```python
import random
import pandas as pd
import datasets
from IPython.display import display, HTML

def show_random_elements(dataset, num_examples=10):
    assert num_examples <= len(dataset), "Can't pick more elements than there are in the dataset."
    picks = []
    for _ in range(num_examples):
        pick = random.randint(0, len(dataset)-1)
        while pick in picks:
            pick = random.randint(0, len(dataset)-1)
        picks.append(pick)

    df = pd.DataFrame(dataset[picks])
    for column, typ in dataset.features.items():
        if isinstance(typ, datasets.ClassLabel):
            df[column] = df[column].transform(lambda i: typ.names[i])
    display(HTML(df.to_html()))

show_random_elements(dataset["train"])
```

### 数据预处理

下载数据集到本地后，使用 Tokenizer 来处理文本，对于长度不等的输入数据，可以使用填充（padding）和截断（truncation）策略来处理。`Datasets`的`map`方法，支持一次性在整个数据集上应用预处理函数。

使用[`google-bert/bert-base-cased`](https://huggingface.co/google-bert/bert-base-cased)的模型对数据进行预处理。

```python
import os

os.environ['HF_HOME'] = './data/hf'
os.environ['HF_HUB_CACHE'] = './data/hf/hub'

from transformers import AutoTokenizer

model_name = 'google-bert/bert-base-cased'
tokenizer = AutoTokenizer.from_pretrained(model_name)

def tokenize_function(examples):
    return tokenizer(examples["text"], padding="max_length", truncation=True)

tokenized_datasets = dataset.map(tokenize_function, batched=True)
```

* `tokenize_function`对数据进行了预处理，长的数据截断，短的数据补0。

显示处理后的数据

```python
show_random_elements(tokenized_datasets["train"], num_examples=1)
```

### 抽样数据

随机抽样1000条数据，用于模型微调

```python
small_train_dataset = tokenized_datasets["train"].shuffle(seed=42).select(range(1000))
small_eval_dataset = tokenized_datasets["test"].shuffle(seed=42).select(range(1000))
```

* `shuffle`随机重新排列数据。

## 模型微调

### 模型微调模块`Trainer`

Transformers Trainer模块可以用于模型微调

```python
from transformers import Trainer

trainer = Trainer(
    model=model,                          # 微调的模型名称
    args=training_args,                   # 训练参数
    train_dataset=dataset["train"],       # 训练数据集
    eval_dataset=dataset["test"],         # 测试数据集
    compute_metrics=compute_metrics,      # 模型评估的指标
)

trainer.train()
```

* 完整的[`training_args`](https://huggingface.co/docs/transformers/v4.36.1/en/main_classes/trainer#transformers.TrainingArguments)，所以的参数都有默认值。

### 指标评估`Evaluate`

[Evaluate](https://huggingface.co/docs/evaluate/index)库是一个用于轻松评估机器学习模型和数据集的Python库。安装Evaluate包

```python
pip install evaluate
```

[Evaluate包含的评估指标](https://huggingface.co/evaluate-metric/spaces?p=0)，可以使用Evaluate库构造compute_metrics，用于模型微调过程的评测。也可供用于模特微调后测试集的总体评测。

### 微调BERT模型

加载BERT模型

```python
```



