# 模型微调入门

## Hugging Face Datasets

[`Datasets`](https://huggingface.co/docs/datasets/index)是一个用于访问和共享音频、计算机视觉和自然语言处理（NLP）任务数据集的Python库，可以方便加载[Hugging Face上的数据集](https://huggingface.co/datasets)。安装`Datasets`包

```shell
pip install datasets
```

* [如何创建自己的`Datasets`](https://huggingface.co/docs/datasets/create_dataset)
* [上传数据到Hugging Face](https://huggingface.co/docs/datasets/upload_dataset)

> [!warning]
>
> `Datasets`使用生成器创建数据集，得到一个可迭代对象。

### 下载训练数据

[`Yelp/yelp_review_full`](https://huggingface.co/datasets/Yelp/yelp_review_full)数据集包括来自Yelp的评论，该数据集主要用于文本分类。有650,000个训练样本和50,000个测试样本。

```python
from datasets import load_dataset

dataset = load_dataset("Yelp/yelp_review_full", cache_dir="./data/hf/datasets")
print(dataset)
```

* `cache_dir="./data/hf/datasets"`指定文件的下载路径。

打印一条数据

```python
print(dataset["train"][0])
```

随机显示10条数据

```python
import random
import pandas as pd
import datasets
from IPython.display import display, HTML

def show_random_elements(dataset, num_examples=10):
    assert num_examples <= len(dataset), "Can't pick more elements than there are in the dataset."
    picks = []
    for _ in range(num_examples):
        pick = random.randint(0, len(dataset)-1)
        while pick in picks:
            pick = random.randint(0, len(dataset)-1)
        picks.append(pick)

    df = pd.DataFrame(dataset[picks])
    for column, typ in dataset.features.items():
        if isinstance(typ, datasets.ClassLabel):
            df[column] = df[column].transform(lambda i: typ.names[i])
    display(HTML(df.to_html()))

show_random_elements(dataset["train"])
```

### 数据预处理

下载数据集到本地后，使用 Tokenizer 来处理文本，对于长度不等的输入数据，可以使用填充（padding）和截断（truncation）策略来处理。`Datasets`的`map`方法，支持一次性在整个数据集上应用预处理函数。

设置下载环境

```python
import os
from transformers import AutoTokenizer
from transformers import AutoModelForSequenceClassification
from transformers import TrainingArguments
import numpy as np
import evaluate
from transformers import Trainer

os.environ['HF_HOME'] = './data/hf'
os.environ['HF_HUB_CACHE'] = './data/hf/hub'
```

使用[`google-bert/bert-base-cased`](https://huggingface.co/google-bert/bert-base-cased)的模型对数据进行预处理。

```python
model_name = 'google-bert/bert-base-cased'
tokenizer = AutoTokenizer.from_pretrained(model_name)

def tokenize_function(examples):
    return tokenizer(examples["text"], padding="max_length", truncation=True)

tokenized_datasets = dataset.map(tokenize_function, batched=True)
```

* `tokenize_function`对数据进行了预处理，长的数据截断，短的数据补0。

显示处理后的数据

```python
show_random_elements(tokenized_datasets["train"], num_examples=1)
```

### 抽样数据

随机抽样1000条数据，用于模型微调

```python
small_train_dataset = tokenized_datasets["train"].shuffle(seed=42).select(range(1000))
small_eval_dataset = tokenized_datasets["test"].shuffle(seed=42).select(range(1000))
```

* `shuffle`随机重新排列数据。

## 模型微调

### 模型微调模块`Trainer`

Transformers Trainer模块可以用于模型微调

```python
from transformers import Trainer

trainer = Trainer(
    model=model,                          # 微调的模型名称
    args=training_args,                   # 训练参数
    train_dataset=dataset["train"],       # 训练数据集
    eval_dataset=dataset["test"],         # 测试数据集
    compute_metrics=compute_metrics,      # 模型评估的指标
)

trainer.train()
```

* 完整的[`training_args`](https://huggingface.co/docs/transformers/v4.36.1/en/main_classes/trainer#transformers.TrainingArguments)，所以的参数都有默认值。

### 指标评估`Evaluate`

[Evaluate](https://huggingface.co/docs/evaluate/index)库是一个用于轻松评估机器学习模型和数据集的Python库。安装Evaluate包

```python
pip install evaluate
```

[Evaluate包含的评估指标](https://huggingface.co/evaluate-metric/spaces?p=0)，可以使用Evaluate库构造compute_metrics，用于模型微调过程的评测。也可供用于模特微调后测试集的总体评测。

### 微调BERT模型

加载BERT模型

```python
model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=5)
```

设置训练参数

```python
model_dir = "./data/hf/models/bert-base-cased-finetune-yelp"
training_args = TrainingArguments(
    output_dir=model_dir, 
    per_device_train_batch_size=16, 
    num_train_epochs=5, 
    logging_strategy="epoch",
    eval_strategy="epoch"
)
print(training_args)
```

定义评估指标

```python
metric = evaluate.load("accuracy")

def compute_metrics(eval_pred):
    logits, labels = eval_pred
    predictions = np.argmax(logits, axis=-1)
    return metric.compute(predictions=predictions, references=labels)
```

训练模型

```python
trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=small_train_dataset,
    eval_dataset=small_eval_dataset,
    compute_metrics=compute_metrics,
)

trainer.train()
```

重新抽取100条数据测试模型

```python
small_test_dataset = tokenized_datasets["test"].shuffle(seed=64).select(range(100))
trainer.evaluate(small_test_dataset)
```

保存训练后的模型

```python
trainer.save_model(model_dir)
```

保存训练状态，保存到`output_dir`目录下。

```python
trainer.save_state()
```

训练状态中包括一些关键信息，可以根据保存的状态恢复，并继续训练。

### 模型微调的流程

1. 整理数据集（决定了模型的上限）。
2. 数据预处理。
3. 配置训练超参数（模型微调的核心）。
4. 设置训练评估指标。
5. 训练模型。
6. 训练完成后，测试训练结果。
7. 模型保存。

## 上下文的问答任务

模型是通过提取上下文的子串来回答问题的，而不是生成新的文本。

<img src="../../images/nlp/question_answering.png" style="zoom:60%;" />

使用[斯坦福问答数据集（SQuAD）](https://rajpurkar.github.io/SQuAD-explorer/)训练微调模型。SQuAD是一个阅读理解数据集，数据出自维基百科文章。

### 数据处理

下载[`squad_v2`](https://huggingface.co/datasets/rajpurkar/squad_v2)数据

```python
dataset = load_dataset(
    "rajpurkar/squad_v2", cache_dir="./data/hf/datasets"
)
print(dataset)
print(dataset["train"][0])
```

显示数据格式

```python
show_random_elements(dataset["train"], num_examples=3)
```

加载分词器

```python
model_name = 'distilbert/distilbert-base-uncased'
tokenizer = AutoTokenizer.from_pretrained(model_name)
print(tokenizer("What is your name?", "My name is Sylvain."))
```

