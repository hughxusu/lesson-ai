# 大模型高效微调

参数高效微调（PEFT，Parameter-Efficient Fine-Tuning）是一种针对大规模预训练模型进行微调的技术，旨在通过仅调整少量参数或引入少量额外参数，去适应新的任务。

PEFT的优点：

1. 节省计算资源和存储：传统微调要保存一份完整模型的参数，而PEFT只需要保存少量新增或修改的参数，节省显著的存储空间。
2. 微调速度更快：调整参数更少，训练时计算量和时间都降低，适合资源有限的环境。
3. 保持预训练知识：冻结大部分预训练模型的权重，防止灾难性遗忘。
4. 适用于低资源场景：可在消费级GPU、边缘设备（如手机、IoT设备）上运行，降低训练和部署成本。

## PEFT主要方

### Adapter Tuning

在Transformer层中插入小型神经网络模块（Adapter），仅训练这些模块。

<img src="https://raw.githubusercontent.com/hughxusu/lesson-ai/develop/images/nlp/Adapter-Tuning.png" style="zoom:95%;" />

1. 模型预训练阶段不加入Adapter。
2. 经典的Adapter就是全连接网络。
3. 在模型微调阶段，根据下游任务的数据训练Adapter，预训练中模型的参数都被冻结。

相关论文：[Parameter-Efficient Transfer Learning for NLP](https://arxiv.org/pdf/1902.00751)

优点

1. 参数高效，仅微调少量参数（通常占主模型的0.1%~1%）。
2. 冻结主模型参数，避免灾难性遗忘，保留预训练学到的通用知识。
3. 多任务适配，同一预训练模型可服务多个任务，只需切换不同的 Adapter。
4. 训练速度快，相比全参数微调，Adapter Tuning的训练时间显著缩短。

缺点

1. 每层增加2个额外矩阵乘法，引入推理延迟。
2. 达能力受限，Adapter限制了其表达能力，可能无法完全适配复杂任务。

### Prefix Tuning

在输入序列前添加一组可学习的“前缀向量”（Prefix），通过调整这些向量来引导模型生成符合任务要求的输出，而无需微调整个模型参数。

<img src="https://raw.githubusercontent.com/hughxusu/lesson-ai/develop/images/nlp/An-illustration-of-prefix-tuning.ppm.png" style="zoom:75%;" />

1. 模型预训练阶段不加入Prefix。
2. Prefix有两种添加方式：
   1. 无投影的Prefix，将Prefix直接拼接到Key和Value上，同时扩展Key和Value的矩阵。
   2. 带投影的Prefix，就是在key和value之前再增加一层全连接矩阵。
3. 在模型微调阶段，训练Prefix参数，预训练中模型的参数都被冻结。

优点

1. 参数高效，仅微调少量参数（通常占主模型的0.1%~1%）。
2. 冻结主模型参数，避免灾难性遗忘，保留预训练学到的通用知识。
3. 训练速度快，相比全参数微调，训练时间显著缩短。
4. 直接控制注意力机制，适合文本生成、对话等任务。

缺点

1. 在非生成任务（如分类）上效果可能不如Adapter。
2. Prefix过长会浪费计算，过短可能表达能力不足。
3. 随机初始化可能导致训练不稳定。

相关论文：[Prefix-Tuning: Optimizing Continuous Prompts for Generation](https://arxiv.org/pdf/2101.00190)

### Prompt Tuning

通过优化连续的软提示（Soft Prompts）来激活模型内部知识，从而适配下游任务，而无需微调整个模型参数。

![](https://raw.githubusercontent.com/hughxusu/lesson-ai/develop/images/nlp/PEPT-Model-Structure-Lester-et-al-2021.jpg)

硬提示（Hard Prompt）：是指以自然语言形式人工设计的提示词，即传统意义上的文本指令或问题模板。

软提示（Soft Prompts：虚拟的token与真实的词表无关，它们本质上是一组独立于词表的可训练参数，通过反向传播学习最优数值，无需对应任何自然语言词汇。

1. 原始输入文本（如句子或问题）通过预训练模型的词嵌入层转换为向量序列。
2. 定义一组可训练的连续向量（软提示），这些向量不是自然语言，而是通过梯度下降优化的高维数值。
3. 将软提示直接拼接到输入向量前。
4. 训练过程中，冻结预训练模型的所有参数，仅优化提示向量。
5. 可以通过计算相似度在词表中查找与软提示向量相近的真实token，但结果通常无实用语义。

优点

1. 参数高效，仅微调少量参数（通常占主模型的0.01%~0.1%）。
2. 冻结主模型参数，避免灾难性遗忘，保留预训练学到的通用知识。
3. 训练速度快，相比全参数微调，训练时间显著缩短。
4. 多任务友好，同一模型只需切换不同软提示即可适配新任务。

缺点

1. 小数据敏感，在极小数据集（如 <100 样本）上可能表现不稳定。
2. 表达能力有限。
3. 提示长度影响大，增加软提示的长度，会导致输入信息下降。

相关论文：[The Power of Scale for Parameter-Efficient Prompt Tuning](https://arxiv.org/pdf/2104.08691)

### LoRA

LoRA（Low-Rank Adaptation）通过低秩矩阵分解模拟全参数微调的效果，仅训练少量参数即可适配下游任务。

<img src="https://raw.githubusercontent.com/hughxusu/lesson-ai/develop/images/nlp/56ccd6fb679.jpeg" style="zoom:55%;" />

预训练模型的权重矩阵$W$，在微调时的变化集中在少数维度上，表示为$\Delta W$，微调后原始权重的前向传播$W$表示为
$$
h=Wx+\Delta Wx
$$
而在微调中$\Delta W$具有低秩特性（即变化集中在少数维度上），所以可以将权重更新分解为两个小矩阵的乘积
$$
\Delta W = A\cdot B
$$
其中$A$和$B$的秩（rank）通常取 1~64（远小于原矩阵维度），所以前向传播可以表示为
$$
h=Wx+(A\cdot B)x
$$
LoRA的$\Delta W$以旁路形式作用于原始权重$W$，与残差网络的残差连接有相似之处。

LoRA在Transformer中的常见添加位置

1. Query和Value矩阵（Key矩阵通常不添加$\Delta W$）。
2. 部分变体会应用于FFN的中间层矩阵。

<img src="https://raw.githubusercontent.com/hughxusu/lesson-ai/develop/images/nlp/lora.png" style="zoom:55%;" />

优点：

1. 参数高效，仅微调少量参数（通常占主模型的0.1%~1%）。
2. 冻结主模型参数，避免灾难性遗忘，保留预训练学到的通用知识。
3. 无推理延迟，合并 $W+AB$后，推理速度与原始模型一致。
4. 多任务适配，同一预训练模型可服务多个任务，只需切换不同的$A$和$B$矩阵 。

缺点

1. 表达能力有限。
2. 超参数敏感，秩（rank）设置不当可能导致训练不稳定或收敛困难。
3. 随着秩增大，LoRA 可能引入与任务无关的噪声幻觉。

相关论文：[LoRA: Low-Rank Adaptation of Large Language Models](https://arxiv.org/pdf/2106.09685)

### LoRA的其它变体

AdaLoRA是LoRA的改进版本，核心思想是动态调整低秩矩阵的秩，自动分配不同层的秩，重要层分配更高秩，次要层降低秩甚至关闭更新。其中采用了复杂的剪枝策略。

相关论文：[AdaLoRA: Adaptive Budget Allocation for Parameter-Efficient Fine-Tuning](https://arxiv.org/pdf/2303.10512)

QLoRA是LoRA的量化升级版，过4-bit量化大幅降低显存占用，使微调超大规模参数成为可能，其性能接近全参数微调。

* 主模型权重$W$被4-bit量化，推理时动态反量化。
* LoRA适配器$\Delta W$不量化，始终保持16-bit（BF16/FP16）精度。

相关论文：[QLoRA: Efficient Finetuning of Quantized LLMs](https://arxiv.org/pdf/2305.14314)
