# 朴素贝叶斯模型

> [!warning]
>
> 朴素贝叶斯模型的一个基本假设是，模型的个特征之间独立。

假设模型有三个特征 $(x_1, x_2, x_3)$，根据独立性有 $P(x_1,x_2,x_3)=P(x_1)\cdot P(x_2)\cdot P(x_3)$​

> [!attention]
>
> 实际应用中很难找到真正独立的特征。

对于两类模型 $y\in(0, 1)$ 的预测概率
$$
P(y=1|X)=\frac{P(y)\cdot P(x|y=1)}{P(X)}=\frac{P(y=1)\cdot P(x_1|y=1)\cdot P(x_2|y=1)\cdot P(x_2|y=1)}{P(X)}
$$
同理可以得出
$$
P(y=0|X)=\frac{P(y=0)\cdot P(x_1|y=0)\cdot P(x_2|y=0)\cdot P(x_2|y=0)}{P(X)}
$$
比较上面量算式的概率就可以判断出在某一特征下不同类别的概率，根据概率的大小做出判断。由于 $P(X)$ 相同，分母的计算可以忽略。

对于上面式子中 $P(x_i|y)$​ 需要根据训练样本的数据得到。$P(y)$ 称为先验概率，可以通过统计得到也可以根据客观规律得出。

假设有若干篇网络文章统计数据如下：

| 特征（关键词） | 科技 | 娱乐 | 总计 |
| -------------- | ---- | ---- | ---- |
| 商场           | 9    | 51   | 60   |
| 影院           | 8    | 56   | 64   |
| 支付宝         | 20   | 15   | 35   |
| 云计算         | 63   | 0    | 63   |
| 总计           | 100  | 121  | 221  |

现在有一篇新的网络文章，包含如下关键词：影院，支付宝，云计算，判断该文章属于：科技类还是娱乐类。

1. 属于科技类的概率 $=$ $P$（影院，支付宝，云计算|科技）$=\frac{8}{100} \times \frac{20}{100} \times \frac{63}{100}\times \frac{100}{221}=0.00456109$​
2. 属于娱乐类的概率 $=$ $P$（影院，支付宝，云计算|娱乐）$=\frac{56}{121} \times \frac{15}{121} \times \frac{0}{121}\times \frac{121}{221}=0$

> [!attention]
>
> 朴素贝叶斯模型本质是利用频率统计来代替概率。学习过程本质就是对数据进行统计，没有反复迭代的学习过程。

> [!note]
>
> 上述求解过程中，数据计算为0可能是样本不足造成的。

为解决训练样本不足问题引入拉普拉斯平滑系数
$$
P(x_i|y)=\frac{N_i+\alpha}{N+\alpha m}
$$
其中 $\alpha$ 为指定系数是 $[0, 1]$ 之间的数，一般取1。$m$ 为文档中的特征词个数。上述过程中统计的文章数量越大，$N$ 和 $N_i$ 的值越大，平滑系数影响越小。

对于连续变量 $x \in (-\infty, +\infty)$ 计算 $P(x|y)$ 需要对 $P(x|y)$ 分布函数进行假设，通常假设为正态分布。根据已有数据计算正太分布的参数 $\mu, \sigma$。计算参数的方法可以使最大似然估计。







好的，下面我将详细介绍如何在 Colab 中使用 Screen，并解决免费版 Colab 无法后台执行的问题。

## 1. 安装 Screen

在 Colab 中，默认情况下可能没有安装 Screen。你需要先安装它：

Bash

```
!apt-get install screen
```

## 2. 创建 Screen 会话

安装完成后，你可以使用 `screen` 命令创建新的会话。你可以为会话指定一个名称，方便后续管理：

Bash

```
!screen -S my_session
```

这将创建一个名为 "my_session" 的新会话。

## 3. 在 Screen 会话中运行你的代码

创建会话后，你会进入 Screen 的命令行界面。在这里，你可以像在正常的 Colab 命令行中一样运行你的代码。例如，你可以运行你的训练脚本：

Bash

```
!python my_training_script.py
```

## 4. 分离 Screen 会话

当你的代码开始运行后，你可以按下 `Ctrl + a`，然后按下 `d` 键，将 Screen 会话分离。这会将你的会话放到后台运行，即使你关闭浏览器或断开连接，会话中的程序也会继续运行。

## 5. 重新连接到 Screen 会话

要重新连接到你的 Screen 会话，可以使用以下命令：

Bash

```
!screen -r my_session
```

这将重新连接到名为 "my_session" 的会话，你可以看到你的程序仍在运行。

## Screen 的其他常用命令

- `screen -ls`：列出所有正在运行的 Screen 会话。
- `screen -X -S my_session quit`：杀死名为 "my_session" 的会话。

## 解决免费版 Colab 无法后台执行的问题

由于免费版 Colab 没有后台执行功能，因此即使你使用了 Screen，仍然可能会因为 Colab 会话超时而被中断。为了解决这个问题，你可以结合以下方法：

1. **定期与 Colab 交互：** 你可以编写一个简单的脚本，定期向 Colab 发送一些请求，以保持会话活跃。例如，你可以使用 JavaScript 代码模拟用户的点击操作。
2. **使用 Google Drive 保存代码和数据：** 将你的训练代码和数据保存在 Google Drive 中，并在 Colab 中加载运行。这样即使会话中断，你也可以重新加载代码和数据，从上次的进度继续训练。
3. **使用 Colab Pro 或 Pro+：** 如果你有条件，可以升级到 Colab Pro 或 Pro+，它们提供更长的会话时间和更稳定的连接，减少因超时导致中断的可能性。

## 总结

通过结合 Screen 和其他方法，你可以有效地解决免费版 Colab 无法后台执行的问题，确保你的长时间任务能够顺利完成。





你好！你使用 ResNet-18 在 CIFAR-10 上训练模型，验证集准确率只有 0.687，这确实偏低，没有充分发挥 ResNet-18 的潜力。 准确率偏低通常意味着模型可能存在以下问题：**欠拟合 (Underfitting) 或训练不足，或者训练配置不佳**。

要提升准确率，我们需要仔细调整训练过程的配置。  以下是一些关键的配置调整方向和建议，可以帮助你提高 ResNet-18 在 CIFAR-10 上的性能：

**1. 增加训练 Epochs (迭代周期):**

- **问题:** 25 个 epochs 对于训练像 ResNet-18 这样较深的模型在 CIFAR-10 上可能 **不够充分**。  模型可能还没有完全收敛，或者说还没有充分学习到数据集的特征。

- **建议:**  **增加训练的 epochs 到 100-200 甚至更多。**  更长的训练时间可以让模型有更多的机会去优化权重，学习更复杂的特征。  你可以尝试逐步增加 epochs，例如先尝试 100 epochs，然后 150 epochs，再到 200 epochs，观察验证集准确率的变化趋势。  如果准确率持续提升，说明增加 epochs 是有效的。

  Python

  ```
  history = res_18.fit(train_images, train_labels,
                      epochs=**100**,  # 增加 epochs 到 100 或更多
                      batch_size=256, validation_data=(val_images, val_labels),
                      verbose=1)
  ```

**2. 增强数据增强 (Data Augmentation):**

- **问题:**  CIFAR-10 数据集相对较小，只有 50,000 张训练图像。  直接使用原始图像训练，模型很容易 **过拟合 (Overfitting) 训练集**，导致在验证集和测试集上泛化能力不足。  数据增强是一种有效的 **正则化方法**，可以人为地增加训练数据的多样性，帮助模型学习更鲁棒的特征，提高泛化能力。

- **建议:**  **添加常见的数据增强操作，例如:**

  - **随机水平翻转 (RandomHorizontalFlip):**  图像水平翻转在 CIFAR-10 这类自然图像数据集上通常很有用。
  - **随机裁剪 (RandomCrop):**  裁剪图像的不同区域，模拟物体在图像中位置和大小的变化。  可以配合 `padding` 操作，在裁剪前先填充图像边缘，保证输出图像尺寸不变。
  - **随机旋转 (RandomRotation):**  小角度的随机旋转。
  - **颜色抖动/颜色增强 (ColorJittering):**  轻微调整图像的亮度、对比度、饱和度、色调等颜色属性。
  - **随机平移 (RandomTranslation):**  在一定范围内随机平移图像。

  在 TensorFlow/Keras 中，你可以使用 `tf.keras.layers.RandomFlip`, `tf.keras.layers.RandomRotation`, `tf.keras.layers.RandomCrop`, `tf.keras.layers.RandomTranslation`, `tf.image.random_brightness`, `tf.image.random_contrast`, `tf.image.random_saturation`, `tf.image.random_hue` 等层来实现数据增强。  可以将这些增强层添加到你的模型的最前端，或者使用 `tf.data.Dataset.map` 方法在数据预处理阶段应用数据增强。

  **示例 (在模型中添加数据增强层):**

  Python

  ```
  class ResNet(keras.Model):
      def __init__(self, num_blocks):
          super(ResNet, self).__init__()
          # 数据增强层添加到模型最前端
          self.data_augmentation = keras.Sequential([
              layers.RandomFlip("horizontal"),
              layers.RandomRotation(0.1),
              layers.RandomTranslation(height_factor=0.1, width_factor=0.1),
              layers.RandomContrast(0.2),
          ])
  
          self.conv = layers.Conv2D(64, kernel_size=3, strides=1, padding='same')
          self.bn = layers.BatchNormalization()
          self.relu = layers.Activation('relu')
          self.mp = layers.MaxPool2D(pool_size=3, strides=2, padding='same')
          # ... (剩余网络层不变) ...
  
      def call(self, x):
          x = self.data_augmentation(x) # 应用数据增强
          x = self.conv(x)
          # ... (剩余网络层不变) ...
          return x
  ```

  或者，你可以使用 `tf.data.Dataset.map` 在数据加载时应用数据增强 (更常用的高效方法，尤其是在处理大型数据集时):

  Python

  ```
  def augment_image(image, label):
      image = tf.image.random_flip_left_right(image)
      image = tf.image.random_crop(image, size=[32, 32, 3]) # 随机裁剪回原始尺寸
      # 可以添加更多增强操作...
      return image, label
  
  batch_size = 256
  train_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_labels))
  train_dataset = train_dataset.map(augment_image).shuffle(buffer_size=10000).batch(batch_size) # 应用数据增强并打乱
  val_dataset = tf.data.Dataset.from_tensor_slices((val_images, val_labels)).batch(batch_size)
  
  history = res_18.fit(train_dataset, epochs=100, validation_data=val_dataset, verbose=1) # 使用 dataset 进行训练
  ```

  **选择哪种数据增强策略和强度，需要根据你的具体数据集和模型进行调整。**  可以尝试不同的增强组合，并观察验证集性能的变化。  通常来说，对于 CIFAR-10，适度的水平翻转、裁剪和颜色增强就能带来比较明显的提升。

  

- 



***\*3. 调整学习率 (Learning Rate) 和学习率衰减策略 (Learning Rate Scheduling):\****



- 

- 

  ***\*学习率过大或过小:\****  你当前使用的学习率 `0.01` 可能对于 ResNet-18 在 CIFAR-10 上的训练来说 ***\*不一定是最优的\****。  学1习率过大可能导致训练不稳定，损失值震荡，难以收敛；学习率过小可能导致训练速度过慢，需要很长时间才能收敛。

- **学习率衰减:**  在训练的早期阶段，可以使用相对较高的学习率，加速模型收敛。  但在训练后期，当模型接近最优解时，应该 **逐渐降低学习率 (学习率衰减)**，更精细地搜索最优解，避免在最优解附近震荡，并提高模型的最终精度。

- **建议:**

  - **尝试更小的初始学习率:**  可以尝试将初始学习率 **降低到 0.001 或 0.0001**。 例如：

    Python

    ```
    optimizer = keras.optimizers.SGD(learning_rate=**0.001**, momentum=0.9, weight_decay=0.0005) # 尝试更小的学习率
    ```

  - **使用学习率衰减策略:**  TensorFlow 提供了多种学习率衰减策略，例如：

    - **Step Decay (阶梯衰减):**  每隔固定 epochs 或 steps 将学习率 **降低一个固定的倍数** (例如 10 倍)。

      Python

      ```
      lr_scheduler = keras.optimizers.schedules.ExponentialDecay(
          initial_learning_rate=0.01,
          decay_steps=10000, # 每 10000 steps 衰减一次
          decay_rate=0.96) # 每次衰减为原来的 0.96 倍
      
      optimizer = keras.optimizers.SGD(learning_rate=lr_scheduler, momentum=0.9, weight_decay=0.0005)
      ```

    - **Cosine Decay (余弦退火):**  学习率按照 **余弦函数** 的形状平滑衰减。

      Python

      ```
      lr_scheduler = keras.optimizers.schedules.CosineDecay(
          initial_learning_rate=0.01,
          decay_steps=epochs * steps_per_epoch) #  总的 decay steps
      optimizer = keras.optimizers.SGD(learning_rate=lr_scheduler, momentum=0.9, weight_decay=0.0005)
      ```

    - **ReduceLROnPlateau (基于验证集性能衰减):**  当验证集性能 **不再提升或提升很小时**，自动降低学习率。  这是更常用的自适应衰减策略。

      Python

      ```
      lr_scheduler = keras.callbacks.ReduceLROnPlateau(
          monitor='val_accuracy', factor=0.1, patience=10, verbose=1, mode='max', min_lr=1e-5) # 当验证集准确率停止提升时，降低学习率
      
      res_18.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])
      history = res_18.fit(train_images, train_labels,
                          epochs=100, batch_size=256, validation_data=(val_images, val_labels),
                          callbacks=[lr_scheduler], #  添加 callback
                          verbose=1)
      ```

  **建议从 `ReduceLROnPlateau` 开始尝试**，它能根据验证集性能自动调整学习率，比较方便有效。  你也可以尝试 `CosineDecay` 或 `Step Decay`， 并根据实验结果选择最佳的学习率策略。

**4.  调整 Weight Decay (权重衰减) 系数:**

- **Weight Decay 的作用:**  你已经使用了 `weight_decay=0.0005`，这是一个 L2 正则化系数，用于控制权重衰减的强度。  权重衰减可以防止模型过拟合，提高泛化能力。
- **调整范围:**  `0.0005` 是一个比较常用的权重衰减系数，但对于不同的数据集和模型，最佳值可能不同。  你可以尝试 **调整 `weight_decay` 的值**，例如尝试 **`0.0001`, `0.001`, 甚至 `0.005`**，观察验证集性能的变化。  通常来说，对于 ResNet 这种深层模型，适度的权重衰减是有益的。
- **实验验证:**  选择不同的 `weight_decay` 值进行实验，并比较验证集准确率，选择性能最佳的值。

**5.  使用更有效的优化器 (Optimizer):**

- **SGD 的局限性:**  你目前使用的是 SGD (随机梯度下降) 优化器，SGD 是一种基本的优化器，但收敛速度可能较慢，并且容易陷入局部最小值。

- **更先进的优化器:**  可以尝试使用更先进的优化器，例如 **AdamW** 或 **Adam**。

  - **AdamW:**  AdamW 优化器在 Adam 的基础上 **解耦了权重衰减 (Weight Decay)**，使得权重衰减的应用更加有效和清晰。 **推荐尝试 AdamW**。  TensorFlow 已经提供了 `AdamW` 优化器。

    Python

    ```
    optimizer = keras.optimizers.AdamW(learning_rate=0.001, weight_decay=0.0005) # 尝试 AdamW 优化器
    ```

  - **Adam:**  Adam 也是一种常用的自适应学习率优化器，通常比 SGD 收敛更快。  可以尝试 Adam 作为另一个选择。

    Python

    ```
    optimizer = keras.optimizers.Adam(learning_rate=0.001, weight_decay=0.0005) # 尝试 Adam 优化器
    ```

  **建议先尝试 AdamW**，它通常在图像分类任务上表现良好，并且自带 Weight Decay 功能，使用起来比较方便。  如果使用 Adam 或 SGD，你需要手动在优化器中设置 `weight_decay` 参数，或者在模型层中使用 `kernel_regularizer` 来应用 L2 正则化。

**6.  调整 Batch Size (批次大小):**

- **Batch Size 的影响:**  你目前使用的 `batch_size=256` 是一个相对较大的批次大小。  Batch Size 影响训练的 **稳定性和速度**。  较大的 Batch Size 可以加速训练，但也可能导致泛化能力略微下降；较小的 Batch Size 可以提高泛化能力，但训练速度会变慢，且训练过程可能更不稳定。
- **尝试调整:**  你可以尝试 **调整 Batch Size**，例如尝试 **128 或 512**。  选择合适的 Batch Size 需要根据你的硬件资源 (GPU 显存) 和实验结果来确定。  通常来说，对于 CIFAR-10， Batch Size 在 128-512 范围内都是可以尝试的。

**7.  模型结构微调 (可选):**

- **更小的模型:**  虽然 ResNet-18 在 CIFAR-10 上通常表现不错，但 CIFAR-10 本身是一个相对简单的数据集。  **或许可以尝试更小的 ResNet 变体，例如 ResNet-14 或 ResNet-8** (如果你的代码支持调整 ResNetBlock 的 `num_residuals` 参数)。  更小的模型参数量更少，训练更快，也更不容易过拟合。
- **修改初始卷积层:**  可以尝试 **修改 ResNet 的初始卷积层** (代码中的 `self.conv`)，例如 **减少初始卷积层的卷积核数量 (例如从 64 降到 32)**， 或者 **使用更小的卷积核尺寸**， 甚至 **去除初始卷积层**，直接从 ResNetBlock 开始。  这些修改可以降低模型的初始复杂度，可能更适合 CIFAR-10 这种小数据集。

**实验流程建议:**

1. **基线模型 (Baseline):**  首先，使用你 **当前的配置 (epochs=25, SGD, lr=0.01, weight_decay=0.0005, batch_size=256, 无数据增强)** 作为一个基线模型，重新训练并记录验证集准确率。

2. 逐个尝试改进:

   每次只修改一个配置参数

   ，例如：

   - **实验 1:**  增加 epochs 到 100 (其他配置保持基线不变)，训练并记录验证集准确率。
   - **实验 2:**  在基线模型基础上，添加数据增强 (例如，水平翻转 + 随机裁剪)，训练并记录验证集准确率。
   - **实验 3:**  在基线模型基础上，使用 AdamW 优化器 (其他配置保持基线不变)，训练并记录验证集准确率。
   - **实验 4:**  在基线模型基础上，使用学习率衰减策略 (例如，ReduceLROnPlateau)，训练并记录验证集准确率。
   - **实验 5:**  在基线模型基础上，调整 weight_decay 到 0.001 (或其他值)，训练并记录验证集准确率。
   - ... (你可以继续尝试调整学习率、Batch Size、甚至模型结构等) ...

3. **比较实验结果:**  比较不同实验的验证集准确率，找到 **对性能提升最有效的配置修改**。

4. **组合优化:**  将多个有效的配置修改 **组合起来**，例如，同时使用 AdamW 优化器、学习率衰减和数据增强，再次训练，看是否能进一步提升性能。

5. **超参数搜索 (可选):**  如果你希望更系统地找到最佳超参数组合，可以使用 **超参数搜索技术 (例如，网格搜索 Grid Search, 随机搜索 Random Search, 贝叶斯优化 Bayesian Optimization 等)**  自动搜索最佳的超参数组合。  但这通常需要更多的计算资源和时间。

**总结和建议优先级:**

为了快速提升 ResNet-18 在 CIFAR-10 上的准确率，**我建议你优先尝试以下配置调整:**

1. **增加训练 Epochs 到 100-200。 (最重要)**
2. **添加数据增强 (水平翻转, 随机裁剪, 适度颜色增强)。 (非常重要)**
3. **尝试使用 AdamW 优化器 (学习率 0.001, weight_decay 0.0005 起始值，可以后续调整)。 (重要)**
4. **使用 `ReduceLROnPlateau` 学习率衰减策略。 (重要)**
5. **适当调整 Batch Size (例如尝试 128 或 512)。 (可选)**
6. **根据实验结果，微调 Weight Decay 系数。 (可选)**
7. **最后，如果性能仍然不理想，再考虑更小的模型结构或更精细的模型架构调整 (可选)。**

**记住，每次只调整一个参数，并观察验证集性能的变化，才能有效分析每个配置修改的影响。  耐心实验和调优，你一定能提升 ResNet-18 在 CIFAR-10 上的准确率!**

祝你训练顺利！
