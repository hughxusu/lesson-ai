{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-08-04T14:03:34.009677Z",
     "start_time": "2025-08-04T14:03:34.008363Z"
    }
   },
   "source": [
    "import os\n",
    "\n",
    "os.environ['HF_HOME'] = './data/hf'\n",
    "os.environ['HF_HUB_CACHE'] = './data/hf/hub'"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "346f8de3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-04T14:03:41.275773Z",
     "start_time": "2025-08-04T14:03:37.164329Z"
    }
   },
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\"sentiment-analysis\")\n",
    "pipe(\"早餐不好,服务不到位,晚餐无西餐,早餐晚餐相同,房间条件不好,餐厅不分吸烟区.房间不分有无烟房.\")"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Device set to use mps:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'NEGATIVE', 'score': 0.9433807730674744}]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "9a77cd42",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-04T08:59:30.178607Z",
     "start_time": "2025-08-04T08:59:30.115075Z"
    }
   },
   "source": [
    "sentence = \"What an absolutely stunning movie, if you have 2.5 hrs to kill, watch it, you won't regret it, it's too much fun!\"\n",
    "pipe(sentence)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9997661709785461}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "95ffa987",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-04T08:59:32.607966Z",
     "start_time": "2025-08-04T08:59:32.549238Z"
    }
   },
   "source": [
    "sentence = \"Kind of drawn in by the erotic scenes, only to realize this was one of the most amateurish and unbelievable bits of film I've ever seen.\"\n",
    "pipe(sentence)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'NEGATIVE', 'score': 0.9985479712486267}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "3e04c338",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-04T08:59:34.717591Z",
     "start_time": "2025-08-04T08:59:34.595159Z"
    }
   },
   "source": [
    "text_list = [\n",
    "    \"This a fantastic movie of three prisoners who become famous.\",\n",
    "    \"A wonderful little production.\",\n",
    "    \"This movie made it into one of my top 10 most awful movies.\"\n",
    "]\n",
    "\n",
    "pipe(text_list)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9998416900634766},\n",
       " {'label': 'POSITIVE', 'score': 0.9998810291290283},\n",
       " {'label': 'NEGATIVE', 'score': 0.8698577284812927}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-04T09:02:34.642889Z",
     "start_time": "2025-08-04T09:02:33.279393Z"
    }
   },
   "cell_type": "code",
   "source": [
    "sentence = \"Hugging Face is a French company based in New York City.\"\n",
    "classifier = pipeline(task=\"ner\")\n",
    "result = classifier(sentence)\n",
    "print(*result, sep='\\n')"
   ],
   "id": "dfd22cbd63b4e13a",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to dbmdz/bert-large-cased-finetuned-conll03-english and revision 4c53496 (https://huggingface.co/dbmdz/bert-large-cased-finetuned-conll03-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Some weights of the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use mps:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'entity': 'I-ORG', 'score': np.float32(0.9967675), 'index': 1, 'word': 'Hu', 'start': 0, 'end': 2}\n",
      "{'entity': 'I-ORG', 'score': np.float32(0.9293029), 'index': 2, 'word': '##gging', 'start': 2, 'end': 7}\n",
      "{'entity': 'I-ORG', 'score': np.float32(0.9763209), 'index': 3, 'word': 'Face', 'start': 8, 'end': 12}\n",
      "{'entity': 'I-MISC', 'score': np.float32(0.99828726), 'index': 6, 'word': 'French', 'start': 18, 'end': 24}\n",
      "{'entity': 'I-LOC', 'score': np.float32(0.99896204), 'index': 10, 'word': 'New', 'start': 42, 'end': 45}\n",
      "{'entity': 'I-LOC', 'score': np.float32(0.9986792), 'index': 11, 'word': 'York', 'start': 46, 'end': 50}\n",
      "{'entity': 'I-LOC', 'score': np.float32(0.9992418), 'index': 12, 'word': 'City', 'start': 51, 'end': 55}\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-04T09:02:38.879002Z",
     "start_time": "2025-08-04T09:02:37.469548Z"
    }
   },
   "cell_type": "code",
   "source": [
    "classifier = pipeline(task=\"ner\", grouped_entities=True)\n",
    "result = classifier(sentence)\n",
    "print(*result, sep='\\n')"
   ],
   "id": "c1adbb6d0907df5d",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to dbmdz/bert-large-cased-finetuned-conll03-english and revision 4c53496 (https://huggingface.co/dbmdz/bert-large-cased-finetuned-conll03-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Some weights of the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use mps:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'entity_group': 'ORG', 'score': np.float32(0.9674638), 'word': 'Hugging Face', 'start': 0, 'end': 12}\n",
      "{'entity_group': 'MISC', 'score': np.float32(0.99828726), 'word': 'French', 'start': 18, 'end': 24}\n",
      "{'entity_group': 'LOC', 'score': np.float32(0.99896103), 'word': 'New York City', 'start': 42, 'end': 55}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xusu/opt/miniconda3/envs/ai/lib/python3.11/site-packages/transformers/pipelines/token_classification.py:186: UserWarning: `grouped_entities` is deprecated and will be removed in version v5.0.0, defaulted to `aggregation_strategy=\"AggregationStrategy.SIMPLE\"` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-04T09:21:18.199240Z",
     "start_time": "2025-08-04T09:21:13.063998Z"
    }
   },
   "cell_type": "code",
   "source": [
    "question_answerer = pipeline(task=\"question-answering\")\n",
    "result = question_answerer(\n",
    "    question=\"What is the name of the repository?\",\n",
    "    context=\"The name of the repository is huggingface/transformers\",\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"score: {round(result['score'], 4)}, start: {result['start']}, end: {result['end']}, answer: {result['answer']}\"\n",
    ")"
   ],
   "id": "1bb9f1d3db5f6978",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-cased-distilled-squad and revision 564e9b5 (https://huggingface.co/distilbert/distilbert-base-cased-distilled-squad).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Device set to use mps:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: 0.9333, start: 30, end: 54, answer: huggingface/transformers\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-04T11:53:45.585855Z",
     "start_time": "2025-08-04T11:53:39.633895Z"
    }
   },
   "cell_type": "code",
   "source": [
    "summarizer = pipeline(task=\"summarization\", model=\"google-t5/t5-base\", min_length=8, max_length=20)\n",
    "summarizer(\n",
    "    \"In this work, we presented the Transformer, the first sequence transduction model based entirely on attention, replacing the recurrent layers most commonly used in encoder-decoder architectures with multi-headed self-attention. For translation tasks, the Transformer can be trained significantly faster than architectures based on recurrent or convolutional layers. On both WMT 2014 English-to-German and WMT 2014 English-to-French translation tasks, we achieve a new state of the art. In the former task our best model outperforms even all previously reported ensembles.\"\n",
    ")"
   ],
   "id": "825ba5c96bc0c832",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n",
      "Your max_length is set to 200, but your input_length is only 128. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=64)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'summary_text': 'the Transformer is the first sequence transduction model based entirely on attention . it replaces recurrent layers commonly used in encoder-decoder architectures with multi-headed self-attention . for translation tasks, the Transformer can be trained significantly faster than architectures based on convolutional layers .'}]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-04T13:46:55.092808Z",
     "start_time": "2025-08-04T13:46:49.605328Z"
    }
   },
   "cell_type": "code",
   "source": [
    "prompt = \"Python is the best programming language.\"\n",
    "\n",
    "generator = pipeline(task=\"text-generation\", model=\"openai-community/gpt2\")\n",
    "generator(prompt)"
   ],
   "id": "1d0a938a679d6ae9",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': \"Python is the best programming language. It's an open-source language that uses libraries and other tools to provide a powerful interface to other languages. A lot of the programming language-oriented tools are written in Python and are used in many different libraries. In addition, Python is a good reference language for understanding other programming languages. The main difference between Python and other programming languages is that Python is built upon the standard library system. You can easily build a full-fledged Python program by using Python's built-in libraries.\\n\\nPython is a library that enables you to use code at runtime. It's not a library to be written in Python; it's an abstraction of the programming language.\\n\\nThe Python API is a set of APIs and APIs can be accessed using any Python programming language.\\n\\nIt's not important to understand how each language handles its own specific problems. It's just that you can use Python and other programming languages to write your own code. You can also use Python for any other programming language (e.g., text editors, web apps).\\n\\nPython is the only programming language that uses a built-in library.\\n\\nIf you are going to build a full-fledged Python program, you should do so using a built-in library.\\n\\nPython's built\"}]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-04T13:47:08.759590Z",
     "start_time": "2025-08-04T13:47:02.836191Z"
    }
   },
   "cell_type": "code",
   "source": [
    "generator = pipeline(\n",
    "    task=\"text-generation\", model=\"openai-community/gpt2\", num_return_sequences=3\n",
    ")\n",
    "result = generator(prompt)\n",
    "print(*result, sep='\\n')"
   ],
   "id": "88549e01163dc3cb",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'generated_text': 'Python is the best programming language. It has many features which make it a great choice for beginners. Here are some of the features that have been added to the language:\\n\\nA simple API for creating and retrieving data.\\n\\nA simple API for creating and retrieving data. A global variable that can be used to control the number of fields in a dataset or an array of data.\\n\\nA global variable that can be used to control the number of fields in a dataset or an array of data. A variable that can be used for data comparison.\\n\\nA variable that can be used for data comparison. A list of variables for a given dataset.\\n\\nA list of variables for a given dataset. A list of possible values for a given variable.\\n\\nA list of possible values for a given variable. A list of possible values for a given array.\\n\\nA list of possible values for a given array. A list of possible values for a given array.\\n\\nA list of possible values for a given array. A list of possible values for a given array.\\n\\nA list of possible values for a given array. A list of possible values for a given array.\\n\\nA list of possible values for a given array. A list of possible values for a given array'}\n",
      "{'generated_text': \"Python is the best programming language.\\n\\nWhat's an HTML page?\\n\\nAn HTML page is an HTML page that contains only one element. An HTML page is an HTML page that contains three or more elements. An HTML page is an HTML page that contains one or more HTML elements.\\n\\nWhat's a page?\\n\\nAn HTML page is an HTML page that contains a single element. An HTML page is an HTML page that contains a single element.\\n\\nWhat's an Element?\\n\\nAn HTML element is a single element. An HTML element is an HTML element that contains a single element.\\n\\nWhat's a page?\\n\\nAn HTML page is an HTML page that contains a single element. An HTML page is an HTML page that contains a single element.\\n\\nWhat's a Page?\\n\\nAn HTML page is an HTML page that contains a single element. An HTML page is an HTML page that contains a single element.\\n\\nWhat's a page?\\n\\nAn HTML page is an HTML page that contains a single element. An HTML page is an HTML page that contains a single element.\\n\\nWhat's an Element?\\n\\nAn HTML element is a single element. An HTML element is an HTML element that contains a single element.\\n\\nWhat's\"}\n",
      "{'generated_text': 'Python is the best programming language. It\\'s fast, compact, and free. It\\'s free for everyone.\\n\\nI wish I could say \"why not?\". It\\'s so simple. It\\'s built on top of the Python programming language and has a great interface. It\\'s easy to use. It\\'s really simple. You can use a custom compiler. It\\'s fast, easy to use, and it makes Python more enjoyable for people who want to write code. You can learn more about Python by reading the Python documentation. There\\'s a lot more to Python than just the language. It\\'s built on top of the Python programming language. It\\'s built on top of the Python programming language.\\n\\nThis is where the Python community comes in. I think this is the \"last bastion of the Python community\". All communities are built around the Python programming language. We don\\'t just want to do Python, we want to write Python code. We want to write code. We want to have a great Python community. We want to have a great Python community.\\n\\nI think people are excited and the community is growing. So I think we\\'re in a position where we\\'re seeing a lot of people who are new to Python. We see new people who haven\\'t seen Python before in the Python'}\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-04T13:52:34.399807Z",
     "start_time": "2025-08-04T13:52:33.889309Z"
    }
   },
   "cell_type": "code",
   "source": [
    "result = generator(prompt, num_return_sequences=2, max_new_tokens=16)\n",
    "print(*result, sep='\\n')"
   ],
   "id": "4186676cc6160790",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'generated_text': 'Python is the best programming language. So far I have been lucky enough to have a great team working on it.'}\n",
      "{'generated_text': 'Python is the best programming language. It has the best features, but it cannot do any real-world things.'}\n"
     ]
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-04T14:04:19.656976Z",
     "start_time": "2025-08-04T14:04:18.840496Z"
    }
   },
   "cell_type": "code",
   "source": [
    "fill_mask = pipeline(task=\"fill-mask\", model=\"google-bert/bert-base-chinese\")\n",
    "fill_mask(\"python是最[MASK]的编程语言\")"
   ],
   "id": "44236238fef0a4ef",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google-bert/bert-base-chinese were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use mps:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'score': 0.6302381157875061,\n",
       "  'token': 3193,\n",
       "  'token_str': '早',\n",
       "  'sequence': 'python 是 最 早 的 编 程 语 言'},\n",
       " {'score': 0.0538448728621006,\n",
       "  'token': 5439,\n",
       "  'token_str': '老',\n",
       "  'sequence': 'python 是 最 老 的 编 程 语 言'},\n",
       " {'score': 0.05048546940088272,\n",
       "  'token': 1962,\n",
       "  'token_str': '好',\n",
       "  'sequence': 'python 是 最 好 的 编 程 语 言'},\n",
       " {'score': 0.049924708902835846,\n",
       "  'token': 1920,\n",
       "  'token_str': '大',\n",
       "  'sequence': 'python 是 最 大 的 编 程 语 言'},\n",
       " {'score': 0.04628099501132965,\n",
       "  'token': 1159,\n",
       "  'token_str': '初',\n",
       "  'sequence': 'python 是 最 初 的 编 程 语 言'}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-04T14:06:04.911756Z",
     "start_time": "2025-08-04T14:06:04.868872Z"
    }
   },
   "cell_type": "code",
   "source": "fill_mask(\"python是[MASK]的编程语言\", top_k=3)",
   "id": "993b74cf94b82f0a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.5506518483161926,\n",
       "  'token': 9030,\n",
       "  'token_str': 'python',\n",
       "  'sequence': 'python 是 python 的 编 程 语 言'},\n",
       " {'score': 0.12401647865772247,\n",
       "  'token': 10515,\n",
       "  'token_str': 'unix',\n",
       "  'sequence': 'python 是 unix 的 编 程 语 言'},\n",
       " {'score': 0.11893767863512039,\n",
       "  'token': 8507,\n",
       "  'token_str': 'java',\n",
       "  'sequence': 'python 是 java 的 编 程 语 言'}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-04T14:24:18.277173Z",
     "start_time": "2025-08-04T14:24:16.299728Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "model_name = \"google-bert/bert-base-chinese\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)"
   ],
   "id": "5dd17166ddceb2dd",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-04T14:26:01.855655Z",
     "start_time": "2025-08-04T14:26:01.852801Z"
    }
   },
   "cell_type": "code",
   "source": [
    "sequence = \"四海之内皆兄弟\"\n",
    "tokens = tokenizer.tokenize(sequence)\n",
    "print(tokens)"
   ],
   "id": "1da8447a59c5bfd9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['四', '海', '之', '内', '皆', '兄', '弟']\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-04T14:29:28.662339Z",
     "start_time": "2025-08-04T14:29:28.660723Z"
    }
   },
   "cell_type": "code",
   "source": [
    "token_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "print(token_ids)"
   ],
   "id": "af463082c9a974de",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1724, 3862, 722, 1079, 4639, 1040, 2475]\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-04T14:32:32.352521Z",
     "start_time": "2025-08-04T14:32:32.350075Z"
    }
   },
   "cell_type": "code",
   "source": [
    "token_ids_e2e = tokenizer.encode(sequence)\n",
    "print(token_ids_e2e)"
   ],
   "id": "f298d5b1492c462a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[101, 1724, 3862, 722, 1079, 4639, 1040, 2475, 102]\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-04T14:34:53.128112Z",
     "start_time": "2025-08-04T14:34:53.126405Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(tokenizer.decode(token_ids))\n",
    "print(tokenizer.decode(token_ids_e2e))"
   ],
   "id": "de06efed34063276",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "四 海 之 内 皆 兄 弟\n",
      "[CLS] 四 海 之 内 皆 兄 弟 [SEP]\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-04T14:37:29.133012Z",
     "start_time": "2025-08-04T14:37:29.130947Z"
    }
   },
   "cell_type": "code",
   "source": [
    "sequence_batch = [\"秦时明月汉时关\", \"万里长征人未还\"]\n",
    "token_ids_batch = tokenizer.encode(sequence_batch)\n",
    "print(tokenizer.decode(token_ids_batch))"
   ],
   "id": "c24e7ac2767031ff",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] 秦 时 明 月 汉 时 关 [SEP] 万 里 长 征 人 未 还 [SEP]\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-04T14:40:26.621899Z",
     "start_time": "2025-08-04T14:40:26.615366Z"
    }
   },
   "cell_type": "code",
   "source": "len(tokenizer.vocab.keys())",
   "id": "b54217786503b5b3",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21128"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-04T14:40:52.656233Z",
     "start_time": "2025-08-04T14:40:52.648365Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from itertools import islice\n",
    "\n",
    "for key, value in islice(tokenizer.vocab.items(), 10):\n",
    "    print(f\"{key}: {value}\")"
   ],
   "id": "eac0b9d0f0d19aa9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "乗: 732\n",
      "肚: 5496\n",
      "弥: 2477\n",
      "阮: 7342\n",
      "焉: 4183\n",
      "##晚: 16298\n",
      "笺: 5020\n",
      "##勸: 14310\n",
      "祕: 4861\n",
      "窍: 4964\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "edb84903488fc2ea"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
