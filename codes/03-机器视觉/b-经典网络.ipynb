{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from torch import nn\n",
    "\n",
    "class ConvRelu(nn.Module):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(ConvRelu, self).__init__()\n",
    "        self.conv = nn.Conv2d(*args, **kwargs)\n",
    "        self.relu = nn.ReLU()\n",
    "        nn.init.kaiming_normal_(self.conv.weight, nonlinearity='relu')\n",
    "        nn.init.zeros_(self.conv.bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.relu(self.conv(x))\n",
    "\n",
    "\n",
    "class LinerRelu(nn.Module):\n",
    "    def __init__(self, *args, dropout=0.5, **kwargs):\n",
    "        super(LinerRelu, self).__init__()\n",
    "        self.lin = nn.Linear(*args, **kwargs)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        nn.init.xavier_normal_(self.lin.weight)\n",
    "        nn.init.zeros_(self.lin.bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.dropout(self.relu(self.lin(x)))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "class AlexNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AlexNet, self).__init__()\n",
    "        self.c1 = ConvRelu(1, 96, kernel_size=11, stride=4)\n",
    "        self.p1 = nn.MaxPool2d(3, 2)\n",
    "        self.c2 = ConvRelu(96, 256, kernel_size=5, padding=2)\n",
    "        self.p2 = nn.MaxPool2d(3, 2)\n",
    "        self.c3 = ConvRelu(256, 384, kernel_size=3, padding=1)\n",
    "        self.c4 = ConvRelu(384, 384, kernel_size=3, padding=1)\n",
    "        self.c5 = ConvRelu(384, 256, kernel_size=3, padding=1)\n",
    "        self.p3 = nn.MaxPool2d(3, 2)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.l1 = LinerRelu(6 * 6 * 256, 4096)\n",
    "        self.l2 = LinerRelu(4096, 4096)\n",
    "        self.l3 = LinerRelu(4096, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.p1(self.c1(x))\n",
    "        x = self.p2(self.c2(x))\n",
    "        x = self.p3(self.c5(self.c4(self.c3(x))))\n",
    "        x = self.flatten(x)\n",
    "        x = self.l3(self.l2(self.l1(x)))\n",
    "        return x"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from torchinfo import summary\n",
    "model = AlexNet()\n",
    "summary(model, (1, 1, 227, 227))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "class AlexNetSmall(nn.Module):\n",
    "    def __init__(self, dropout=0.5):\n",
    "        super(AlexNetSmall, self).__init__()\n",
    "        self.c1 = ConvRelu(1, 96, kernel_size=11, stride=4)\n",
    "        self.p1 = nn.MaxPool2d(3, 2)\n",
    "        self.c2 = ConvRelu(96, 256, kernel_size=5, padding=2)\n",
    "        self.p2 = nn.MaxPool2d(3, 2)\n",
    "        self.c3 = ConvRelu(256, 384, kernel_size=3, padding=1)\n",
    "        self.c4 = ConvRelu(384, 384, kernel_size=3, padding=1)\n",
    "        self.c5 = ConvRelu(384, 256, kernel_size=3, padding=1)\n",
    "        self.p3 = nn.MaxPool2d(3, 2)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.l1 = LinerRelu(256, 128, dropout=dropout)\n",
    "        self.l2 = LinerRelu(128, 128, dropout=dropout)\n",
    "        self.l3 = LinerRelu(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.p1(self.c1(x))\n",
    "        x = self.p2(self.c2(x))\n",
    "        x = self.p3(self.c5(self.c4(self.c3(x))))\n",
    "        x = self.flatten(x)\n",
    "        x = self.l3(self.l2(self.l1(x)))\n",
    "        return x"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "model_small= AlexNetSmall()\n",
    "summary(model_small, (1, 1, 67, 67))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "%run utils.py"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from torchvision import datasets, transforms\n",
    "from utils import train_val_split\n",
    "\n",
    "full = datasets.FashionMNIST(root='./data', train=True, download=True)\n",
    "test = datasets.FashionMNIST(root='./data', train=False, download=True)\n",
    "train, valid = train_val_split(full, seed=666)\n",
    "\n",
    "print(len(train), len(valid), len(test))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from utils import PackDataset\n",
    "\n",
    "trans = transforms.Compose([transforms.Resize(size=67), transforms.ToTensor()])\n",
    "train_data = PackDataset(train, transform=trans)\n",
    "valid_data = PackDataset(valid, transform=trans)\n",
    "test_data = PackDataset(test, transform=trans)\n",
    "\n",
    "image, label = train_data[0]\n",
    "print(image.size())"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from skorch.callbacks import EarlyStopping, Checkpoint, EpochScoring, LRScheduler, ProgressBar\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "\n",
    "def control_callbacks(\n",
    "        epochs, show_bar=True,\n",
    "        model_name='best_model.pt', check_dir='./data/checkpoints'\n",
    "    ):\n",
    "    bar = ProgressBar()\n",
    "    lr_scheduler = LRScheduler(policy=CosineAnnealingLR, T_max=epochs)\n",
    "    early_stopping = EarlyStopping(monitor='valid_acc', lower_is_better=False, patience=6)\n",
    "    train_acc = EpochScoring(name='train_acc', scoring='accuracy', on_train=True)\n",
    "    check_point = Checkpoint(\n",
    "        dirname=check_dir, f_params=model_name,\n",
    "        monitor='valid_acc_best', load_best=True\n",
    "    )\n",
    "    calls = []\n",
    "    if show_bar:\n",
    "        calls.append(bar)\n",
    "    calls.extend([lr_scheduler, early_stopping, train_acc, check_point])\n",
    "    return calls"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import torch\n",
    "from skorch import NeuralNetClassifier\n",
    "from skorch.helper import predefined_split\n",
    "\n",
    "epochs = 50\n",
    "calls = control_callbacks(epochs, check_dir='./data/alex-checkpoints')\n",
    "net = NeuralNetClassifier(\n",
    "    AlexNetSmall,\n",
    "    criterion=nn.CrossEntropyLoss,\n",
    "    optimizer=torch.optim.Adam,\n",
    "    lr=0.001,\n",
    "    batch_size=2048,\n",
    "    max_epochs=epochs,\n",
    "    train_split=predefined_split(valid_data),\n",
    "    device='cuda' if torch.cuda.is_available() else 'cpu',\n",
    "    callbacks=calls,\n",
    "    classes=list(range(10)),\n",
    ")\n",
    "net.fit(X=train_data, y=None)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_history(net):\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "    ax1.plot(net.history[:, 'train_loss'], label='Train Loss', linewidth=3)\n",
    "    ax1.plot(net.history[:, 'valid_loss'], label='Valid Loss', linewidth=3)\n",
    "    ax1.set_xlabel('Epoch', fontsize=14)\n",
    "    ax1.set_ylabel('Loss', fontsize=14)\n",
    "    ax1.set_title('Training & Validation Loss', fontsize=16)\n",
    "    plt.xticks(fontsize=14)\n",
    "    plt.yticks(fontsize=14)\n",
    "    ax1.legend()\n",
    "\n",
    "    ax2.plot(net.history[:, 'train_acc'], label='Train Accuracy', linewidth=3)\n",
    "    ax2.plot(net.history[:, 'valid_acc'], label='Valid Accuracy', linewidth=3)\n",
    "    ax2.set_xlabel('Epoch', fontsize=14)\n",
    "    ax2.set_ylabel('Accuracy (%)', fontsize=14)\n",
    "    ax2.set_title('Validation Accuracy', fontsize=16)\n",
    "    plt.xticks(fontsize=14)\n",
    "    plt.yticks(fontsize=14)\n",
    "    ax2.legend()\n",
    "\n",
    "    plt.tight_layout() \n",
    "    plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "plot_history(net)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "def check_result(net, test_data):\n",
    "    y_pred = net.predict(test_data) \n",
    "    y_prob = net.predict_proba(test_data) \n",
    "    y_true = np.array([y for x, y in iter(test_data)])     \n",
    "    test_accuracy = accuracy_score(y_true, y_pred)\n",
    "    print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "    print('='*100)\n",
    "\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    print(\"Confusion Matrix:\\n\", cm)\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    sns.heatmap(\n",
    "        cm, \n",
    "        annot=True, \n",
    "        fmt=\"d\", \n",
    "        cmap=\"Blues\",\n",
    "        annot_kws={\"size\": 10},\n",
    "    )\n",
    "    plt.xlabel(\"Predicted Label\", fontsize=14)\n",
    "    plt.ylabel(\"True Label\", fontsize=14)\n",
    "    plt.title(\"Confusion Matrix (Test Set)\", fontsize=16)\n",
    "    plt.xticks(fontsize=14)\n",
    "    plt.yticks(fontsize=14)\n",
    "    plt.show()\n",
    "    print('='*100)\n",
    "    y_hat = np.asarray(y_true)                 \n",
    "    wrong_idx = np.where(y_pred != y_hat)[0]\n",
    "    error_list = []\n",
    "    for i in wrong_idx:\n",
    "        features, _ = test_data[i]                  \n",
    "        error_list.append({\n",
    "            \"features\": features,              \n",
    "            \"true_label\": int(y_hat[i]),\n",
    "            \"pred_label\": int(y_pred[i]),\n",
    "            \"probabilities\": y_prob[i]      \n",
    "        })\n",
    "\n",
    "    print(f'error number: {len(error_list)}')\n",
    "    return error_list"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "check_result(net, test_data)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "\n",
    "epochs = 1\n",
    "param_grid = {\n",
    "    'lr': [0.01, 0.005],\n",
    "    'batch_size': [2048],\n",
    "}\n",
    "\n",
    "results = {\n",
    "    'best_params': None,\n",
    "    'best_acc': 0.0,\n",
    "    'all_results': []\n",
    "}\n",
    "\n",
    "for params in ParameterGrid(param_grid):\n",
    "    print(f\"\\nTraining with params: {params}\")\n",
    "\n",
    "    net = NeuralNetClassifier(\n",
    "        AlexNetSmall,\n",
    "        criterion=nn.CrossEntropyLoss,\n",
    "        optimizer=torch.optim.Adam,\n",
    "        lr=params['lr'],\n",
    "        batch_size=params['batch_size'],\n",
    "        max_epochs=epochs,\n",
    "        train_split=predefined_split(valid_data),\n",
    "        device='cuda' if torch.cuda.is_available() else 'cpu',\n",
    "        callbacks=calls,\n",
    "        classes=list(range(10)),\n",
    "    )\n",
    "    net.fit(X=train_data, y=None)\n",
    "    valid_acc = max(net.history[:, 'valid_acc'])\n",
    "    current_result = {'params': params, 'valid_acc': valid_acc}\n",
    "    results['all_results'].append(current_result)\n",
    "\n",
    "    if valid_acc > results['best_acc']:\n",
    "        results['best_acc'] = valid_acc\n",
    "        results['best_params'] = params\n",
    "\n",
    "    print(f\"\\nBest params: {results['best_params']}, best acc: {results['best_acc']}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
